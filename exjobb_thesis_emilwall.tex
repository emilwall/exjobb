% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode
% arara: pdflatex: { draft: true }
% arara: biber
% arara: pdflatex: { synctex: true }
% arara: pdflatex: { synctex: true }

\documentclass[11pt]{article}

\usepackage[swedish,english]{babel} % Enables swedish typesetting, needs to be at top of document
\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX
\usepackage{textcomp} % Suppress unicode char error
\usepackage{enumitem} % resume numbering in enumerations
\usepackage[bottom = 110pt]{geometry} % to change the page dimensions
\geometry{a4paper} % paper format, could also be placed in documentclass options
\usepackage{graphicx} % support the \includegraphics command and options
\usepackage[parfill]{parskip} % Begin paragraphs with an empty line rather than an indent
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{verbdef} % inline verbatim
%\usepackage{titling} % required for setlength droptitle (below)
%\setlength{\droptitle}{-70pt} % Adjust title height
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{} % fancyhdr style reset for header
\lfoot{}\cfoot{\thepage}\rfoot{} % fancyhdr style reset for footer
\usepackage{sectsty} % Section title
\allsectionsfont{\sffamily\mdseries\upshape} % Section font
\usepackage{hyperref} % href
\usepackage{nameref} % Enable referring to the actual name of the chapter
\usepackage[backend=biber,sorting=none]{biblatex}
\bibliography{references.bib}
\usepackage{url}

\title{How to test your JavaScript}
\author{Emil Wall}
%\date{} % Uncomment to hide date, or provide a date to display

\begin{document}
\pagenumbering{gobble} % Turn off page numbering

\maketitle

\vspace{100pt}
The final version will have title page and endpaper generated from \\
\url{http://pdf.teknik.uu.se/pdf/exjobbsframsida.php} and \\
\url{http://pdf.teknik.uu.se/pdf/abstract.php}. \\
Hence, this page and the abstract are temporary, to be replaced in the final version.

\newpage
\clearpage\mbox{}\clearpage
\newpage

\begin{abstract}
Abstract goes here... Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam sollicitudin varius libero ac consectetur. Nullam ornare, massa et sagittis consectetur, neque mi scelerisque arcu, in fringilla lectus risus non arcu. Suspendisse vestibulum tellus id mauris lacinia non hendrerit nibh tempor. Proin tempor interdum justo et elementum. Ut ultricies adipiscing ipsum et pharetra. Vestibulum pretium luctus est, quis egestas augue luctus et. Praesent volutpat pharetra lectus vitae elementum.

Integer fringilla ligula eu sem semper tincidunt. Nullam mi lacus, blandit non sollicitudin eget, tempor eu ante. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Morbi ornare sem et purus consequat ac adipiscing nunc tincidunt. Curabitur nisi ante, ornare vel adipiscing et, scelerisque vitae erat. Etiam blandit egestas magna, quis dapibus nulla euismod quis. Sed interdum interdum malesuada. Suspendisse lacinia imperdiet laoreet. Maecenas ullamcorper laoreet nunc ac egestas. Cras consequat elit eu lacus sollicitudin ut pharetra magna venenatis. Suspendisse scelerisque condimentum pulvinar. Mauris ut tellus sit amet nulla porttitor tristique. Suspendisse eleifend erat sed nisi lacinia eu lacinia metus porta. Nulla pretium, risus eget semper laoreet, dolor odio malesuada eros, at mattis enim turpis gravida felis. Aliquam adipiscing varius nibh, ac auctor eros bibendum non.
\end{abstract}

\newpage
\clearpage\mbox{}\clearpage
\newpage

\section*{Acknowledgment}

Thanks goes to my supervisor Jimmy Larsson for providing me with valuable feedback and connections, to my reviewer Roland Bol for guiding me through the process and giving useful and constructive comments on my work, to the people I have had contact with and interviewed as part of this work, to all my wonderful colleagues at Valtech which never fails to surprise me with their helpfulness and expertise, and to my family and friends (and cats!) for all the little things that ultimately matters the most.

\newpage
\clearpage\mbox{}\clearpage
\newpage

\tableofcontents

\newpage
\clearpage\mbox{}\clearpage
\newpage

\pagenumbering{arabic} % Turn page numbering back on

\section{Introduction}

The testing community around JavaScript still has some ground to cover. The differences in testing ambitions becomes especially clear when compared to other programming communities such as Ruby and Java. As illustrated by Mark Bates\cite{TestingStatistics}:

\begin{quote}
``Around the beginning of 2012, I gave a presentation for the Boston Ruby Group, in which I asked the crowd of 100 people a few questions. I began, `Who here writes Ruby?' The entire audience raised their hands. Next I asked, `Who tests their Ruby?' Again, everyone raised their hands. ``Who writes JavaScript or CoffeeScript?' Once more, 100 hands rose. My final question: `Who tests their JavaScript or CoffeeScript?' A hush fell over the crowd as a mere six hands rose. Of 100 people in that room, 94\% wrote in those languages, but didn't test their code. That number saddened me, but it didn't surprise me.''
\end{quote}

JavaScript is a scripting language primarily used in web browsers to perform client-side actions not feasible through plain HTML and CSS. Due to the dynamic nature of the language, there is typically little static analysis performed on JavaScript code aside from the usage of lint tools (see section~\ref{sec:Lint}). There are benefits of testing code in general, for reasons that we will come back to, but JavaScript is particularly important to test properly due to its dynamic properties, complicated syntax \cite[questions~1-3]{Stenmark} and poor object orientation support. Despite the wide variety of testing frameworks that exists for JavaScript, it is generally considered that few developers use them. The potential risk of economic loss associated with untested code being put into production, due to undetected bugs, shortened product lifetime and increased costs in conjunction with further development and maintenance, constitutes the main motivation for this thesis.

\subsection{Motivation}

Why testing, you may ask. Jack Franklin, a young JavaScript blogger from the UK, gives three reasons: it helps you to plan out your APIs, it allows you to refactor with confidence, and it helps you to discover regression bugs (i.e. when old code breaks because new code has been added). Writing tests to use a library before actually writing the library puts focus on intended usage, leading to a cleaner API. Being able to change and add code without fear of breaking something greatly accelerates productivity, especially for large applications. \cite{JackFranklin}

More than 90 \% of today's websites use JavaScript\cite{BusinessJavascript} and its applications have become increasingly complex \cite[question~23]{Ekelof}. There is an economic risk with untested JavaScript that is especially high when the code supports business critical operations. For instance, there have been several cases of banks and finance systems being fined for not reporting transactions to the government\cite{Bug1} or giving faulty advice to investors\cite{Bug2} due to application failure. A webshop may lose orders and any website that is perceived as broken can harm trademarks associated with it and change people's attitudes for the worse. When automatic regression tests are missing, making changes to the code is error prone. Issues related to browser compatibility or subtle dependencies between functions and events are easily overlooked, issues that can be detected by tests prior to setting the site into production. Manually testing a web page with all the targeted combination of browsers, versions and system platforms is usually not a viable option\cite{TestSwarm} so multi-platform automated testing is required.

To achieve maximal gain from testing, the tests need to be of high quality, which means that they should be maintainable and test the right thing. Otherwise, responding to changes is harder, and the tests will tend to cause frustration among the developers instead of detecting bugs and driving the understanding and development of the software\cite{Clean}. The criteria for maintainability in this context are that the tests should have low complexity (typically short test methods without any control flow), consist of readable code, use informative variable names, have reasonably low level of repeated code (this can be accomplished through using Test Utility Methods\cite[599]{TestPatterns}), be based on interfaces rather than a specific implementation and have meaningful comments (if any). Structuring the code according to a testing pattern such as the Arrange-Act-Assert\cite{C2} and writing the code so that it reads like sentences will help in making the code more readable, in essence by honouring the communicate intent principle\cite[p.~41]{TestPatterns}. Testing the right thing means focusing on the behaviour that provides true business value rather than trying to fulfill some coverage criteria, testing that the specification is fulfilled rather than a specific implementation and to find a balance in the amount of testing performed in relation to the size of the system under test. Typically some parts of the system will be more complex and require more rigorous testing but there should be some level of consistency in the level of ambition regarding testing across the entire application. Specifically, if some part of the code is hard to test it is likely to be beneficial in the long run to refactor the design to provide better testability than to leave the code untested.

Unit testing is particularly powerful when in combination with integration tests in a CI build\footnote{Continuous Integration build servers are used for automatic production launch}. This enables you to harness the power of CI, avoiding errors otherwise easily introduced as changes propagate and affect other parts of the system in an unexpected way. The integration tests will make developers aware if they are breaking previous functionality, when changing parts of the system that the JavaScript depends upon.

Testing JavaScript paves the way for test-driven development, which brings benefits in terms of the design becoming more refined and increased maintainability. Tests can serve as documentation for the code and forcing it to be written in a testable manner, which in itself tends to mean adherence to key principles such as separation of concerns, and single responsibility.

The goal with this thesis is to investigate why JavaScript testing has been performed to such a small extent, and what potential implications an increased amount of testing could provide for development and business value. Providing possible approaches to testing JavaScript under different conditions are also part of the goal. % TODO elaborate and update

\subsection{Background to project}

The first known testing framework JsUnit was created in 2001 by Edward Hieatt\cite{GoingFaster,JsUnitGithub} and since then several other test framework has appeared such as the testing framework for jQuery, which goes under the name QUnit \cite{QUnitSite}, and JsUnits sequel Jasmine \cite{JasmineSite}. There are also tools for mocking (see section~\ref{sec:mocking}) such as Sinon.JS\cite{SinonJS}. It seems as if the knowledge of how to smoothly get started, how to avoid making the tests non-deterministic and time consuming, and what to test, is rare. Setting up the structure needed to write tests is a threshold that most JavaScript programmers do not overcome\cite{TestingStatistics} and thus, they lose the benefits, both short and long term, otherwise provided by testing.

In guides on how to use different JavaScript testing frameworks, examples are often decoupled from the typical use of JavaScript - the Web. They tend to merely illustrate testing of functions without side effects and dependencies. Under these circumstances, the testing is trivial and most JavaScript programmers would certainly be able to put up a test environment for such simple code. In contrast, the problem domain of this thesis is to focus on how to test the behaviour of JavaScript that manipulates DOM elements (Document Object Model, the elements that html code consists of), interacts with databases and fetches data using asynchronous calls, as well as when and why you should do it.

\section{Description of Work}

Researching today's limited testing of JavaScript may be done from a multiple different points of view. There are soft aspects such as:
\begin{itemize}
\item Differences in attitudes towards testing between different communities and professional groups
\item How JavaScript is typically conceived as a language and how it is used
\item Knowledge about testing among JavaScript developers
\item Economic viability and risk awareness
\end{itemize}

There are also more technical aspects:
\begin{itemize}
\item Testability of JavaScript code written without tests in mind
\item Usability of testing tools and frameworks
\item Reasons not to include frameworks in a project for the sole purpose of facilitating testing
\item Limitations in what can be tested
\item Complexity in setting up the test environment; installing frameworks, configuring build server, exposing functions to testing but not to users in production, etc.
\end{itemize}

\subsection{Consequences of JavaScript testing}

There are consequences (good and bad) of testing JavaScript both from a short and from a longer perspective. The development process is affected; through time spent thinking about and writing tests, shorter feedback loops, executable documentation and new ways of communicating requirements with customers. The business value of the end result is also likely to be affected, as well as the quality and maintainability of the code. Ideally, the pace of development does not stagnate and making changes becomes easier when the application is supported by a rigorous set of tests. The extra time required to set up the test environment and write the actual tests may or may not turn out to pay off, depending on how the application will be used and maintained.

\subsection{Covering common and advanced cases}

Accounting for how to conveniently proceed with JavaScript testing should cover not only the simplest cases but also the most common and the hardest ones, preferably while also providing evaluation and introduction to available tools and frameworks. Many introductions and tutorials found for the testing frameworks today tends to focus on the simple cases of testing, possibly because making an impression that the framework is simple to use has been more highly prioritised than covering different edge cases of how it can be used that might not be relevant to that many anyway. To provide valuable guidance in how to set up a testing environment and how to write the tests, attention must be paid to the varying needs of different kinds of applications. It is also important to keep in mind that the tests should be as maintainable as the system under test, to minimise maintenance costs and maximise gain.

\section{Technical background}

This section gives an overview of concepts and tools relevant to understanding this thesis. Readers with significant prior knowledge about JavaScript testing may skip this section.

\subsection{Lint tools for JavaScript}
\label{sec:Lint}

Linting is a static analysis tool for detecting syntax errors, risky programming styles and failure to comply to coding conventions. There are lint tools available for JavaScript such as JSLint, JSHint, JavaScript Lint, JSure, the Closure compiler and PHP CodeSniffer. JSLint does provide some help to avoid common programming mistakes, but does not perform flow analysis\cite{JSLint} and type checking as a fully featured compiler would do, rendering proper testing routines the appropriate measure against programming mistakes.

\subsection{Mocking and Stubbing}
\label{sec:mocking}

Mocking and stubbing involves simulation of behavior of real objects in order to isolate the system under test from external dependencies.

\subsection{Browser Automation}
\label{sec:browserautomation}

Repetitive manual navigation of a web site is generally boring and time consuming. There are situations where manual testing is the right thing to do, such as when there is no need for regression testing or the functionality is too complicated to interact with for automated tests to be possible (but then the design should probably be improved). Most of the time, tasks can be automated. There are several tools available for automating a web browser: the popular open source Selenium WebDriver, the versatile but proprietary and windows specific TestComplete and Ranorex, the Ruby library Watir and its .NET counterpart WatiN, and others such as Sahi and Windmill.

Selenium WebDriver is a collection of language specific bindings to drive a browser, which includes an implementation of the W3C WebDriver specification. It is based on Selenium RC, which is a deprecated technology for controlling browsers using a remote control server. A common way of using Selenium WebDriver is for user interface and integration testing, by instantiating a browser specific driver, using it to navigate to a page, interacting with it using element selectors, key events and clicks, and then inspecting the result through assertions. These actions can be performed in common unit testing frameworks in Java, C\nolinebreak\hspace{-.05em}\raisebox{.3ex}{\scriptsize\bf \#}, Ruby and Python through library support that uses the Selenium-Webdriver API. \cite{Selenium}

There is also a Firefox plugin called Selenium IDE, that allows the user to record interactions and generate code for them that can be used to repeat the procedure or as a starting point in tests. In the remaining parts of this thesis, we will mean Selenium WebDriver when we say Selenium, and refer to Selenium IDE by its full name.

\subsection{The DOM}
\label{sec:dom}

The Document Object Model (DOM) is ... % TODO

\section{Methods}

The methods used are first and foremost qualitative in nature, in order to prioritise insight into the problem domain above quantitatively verifying hypotheses. The chance of finding out the true reasons to why JavaScript is tested to such a small extent increases with open questions. Specifically, aside from literature studies, the main method of this thesis work has been to perform and analyse interviews of JavaScript programmers (mainly those concerned with user interface). There has also been some hands on evaluation of tools and frameworks, and assessment of testability and impact of adding tests to existing projects. In order to describe methods of writing tests for JavaScript, the practical work involved testing an existing application, performing TDD as described in Test-driven JavaScript Development\cite{Tddjs} and doing some small TDD projects during the framework evaluation. Another method used was a workshop field study, where programmers were allowed to work in pairs to solve pre-defined problems using TDD.

The following testing frameworks have been evaluated: Jasmine\cite{JasmineSite} (+ Jasmine-species\cite{JasmineSpecies}), qUnit\cite{QUnitSite}, Karma\cite{KarmaSite}, Mocha\cite{MochaSite}, JsTestDriver\cite{JsTestDriver}, Buster.JS\cite{BusterJS} and Sinon.JS\cite{SinonJS}. The code written while evaluating the frameworks is publicly available as git repositories under my github account \emph{emilwall}, together with the \LaTeX~code for this report.

Semi-structured interviews were used rather than surveys to gather individual views on the subject. This approach allowed for harnessing unique as well as common experiences which would not be picked up in a standardised survey.

\subsection{Interview Considerations}

The preparations before the interviews where included specifying purpose and which subjects to include, select interviewees, put together questions and other material and adjust the material to fit each interviewee. The interviews took place rather late to ensure that the interviewer could obtain a solid background and domain knowledge. Each interview was summarised in writing and the collected material was structures and analysed to increase conciseness of results.

\subsection{Interview Questions}

\subsubsection{Formalities}
The interviews took place in calm, undisturbed locations, and began with a short recap on the background and purpose of the interviews. The interviewee was informed that the purpose of the interview was to gain a better understanding of different aspects of JavaScript testing. What problems and benefits exists and how it is connected with other software engineering practices and tools.

\begin{itemize}
\item Is it ok if I record our conversation?
\item Do you want to be anonymous?
\end{itemize}

\subsubsection{The interviewee}
\begin{itemize}
\item What kind of applications do you typically develop with JavaScript?
\item What tools and frameworks have you used? What roles have they played in your development processes?
\item Which are your favourites among the frameworks? Why?
\end{itemize}

\subsubsection{JavaScript in general}
\begin{itemize}
\item How productive do you feel when coding in JavaScript compared to other languages?
\item How do you typically perceive JavaScript code written by others?
\item What advanced features of JavaScript do you use, such as prototypal inheritance, dynamic typing and closures?
\item How do you think the JavaScript syntax and features impacts maintainability?
\item How would you assess the probability of making mistakes while coding in JavaScript?
\end{itemize}

\subsubsection{JavaScript testing experience}
\begin{itemize}
\item What is your experience with unit testing of JavaScript?
\item What is your experience with UI testing?
\item What is your experience with integration and end-to-end tests?
\item Have you practiced test driven development with JavaScript? To what extent? Has this been helpful? (if not, why? what did you do instead?)
\item Have you used any mocking and stubbing tools? Which, and what has been your experience with these?
\end{itemize}

\subsubsection{Challenges in testing}
\begin{itemize}
\item How do you go about determining what to test?
\item What principles do you apply when writing the tests? (short test methods, avoiding control flow, code duplication)
\item Have you ever set up a testing environment? If so, did you find it hard? If not, do you imagine it to be difficult?
\end{itemize}

\subsubsection{Benefits of testing}
\begin{itemize}
\item In your opinion, what are the main benefits from testing your JavaScript?
\item When do you think testing JavaScript pays off?
\item Have you ever had tests that impaired your productivity by being too hard to change or even understand?
\item Has tests helped you in debugging and quickly finding the source of a bug?
\item Has testing helped you discover bugs in the first place? Has this saved you from trouble further on?
\item Has testing helped your design?
\item What role has JavaScript testing played in any continuous integration you've had?
\item What type of JavaScript coding do you think is best suited for TDD?
\end{itemize}

\subsubsection{Adding tests to existing application}
\begin{itemize}
\item Have you ever been given the task of adding tests to an existing (JavaScript) application?
\item Was this hard?
\item What changes in the application were required in order to be able to write the tests?
\item Did you feel safe in changing the application or were you afraid that you'd might introduce new bugs?
\end{itemize}

\subsection{The interviewees}

In order to find people to interview; I enquired in Valtech's intranet, my supervisor asked his contacts via his Twitter account and I contacted some people via mail. It led to five interviews and one email conversation, which can be found in the Appendix.

The first person I interviewed was Johannes Edelstam, an experienced Ruby and JavaScript developer, organizer of the sthlm.js meetup group and a former employee of Valtech, now working at Tink. He has a positive attitude towards JavaScript as a programming language and has extensive experience of test driven development.

\section{Previous work and Delimitations}

There exists academic papers on testing web applications and a few focus on JavaScript specifically. Some focus on automatically generating tests\cite{AutomatedTesting} and although useful for meeting code coverage criteria, these methods will not be discussed to any great length here since such tests are hard to maintain and likely to cause false positives when refactoring code. In this thesis, there will be more focus on how to employ test driven development than achieving various degrees of code coverage.

Heidegger et al. cover unit testing of JavaScript that manipulates the DOM of a web page\cite{DOMJavascript} and Ocariza et al. have investigated frequency of bugs in live web pages and applications\cite{Wild}. These are of more interest to this thesis since they are aimed at testing of client side JavaScript that runs as part of web sites.

The main source of reference within the field of JavaScript testing today is Test-Driven JavaScript Development\cite{Tddjs} by Christian Johansen which deals with JavaScript testing from a TDD perspective. Johansen is the creator of Sinon.JS\cite{SinonJS} and a contributor to a number of testing frameworks hosted in the open source community.

The scope of this thesis has been to look mainly at testing of \emph{client side} JavaScript. This meant that framework specialised for server side code such as vows\cite{Vows} and cucumis\cite{Cucumis} are not included in the evaluation part. Testing client side code is by no means more important than the server side, but it can be argued that it is often harder and the parallels to testing in other languages are somewhat fewer since the architecture typically is different.

Frameworks that are no longer maintained such as JsUnit\cite{JsUnitGithub} and JSpec\cite{JSpec} have deliberately been left out of the evaluation. Others have been left out because of fewer users or lack of unique functionality; among these we find TestSwarm, YUI Yeti and RhinoUnit. They are still useful tools that can be considered but including them would have a negative impact on the rest of the evaluation work because of the extra time consuming activities that would be imposed.

\section{Analysis of Economic Impacts}

\begin{itemize}
  \item Identify cases where companies and authorities have suffered economic loss due to bugs in JavaScript code vital to business critical functions of web sites
  \item Assess risks and undocumented cases of manifested bugs
  \item Estimate maintenance costs of code that lack tests compared to well-tested code
  \item Draw conclusions about how test-driven development can either shorten or prolong the time required to develop a product, depending on programmer experience and the size and type of the application being developed
  \item Costs associated with acquiring developers with the skills necessary to write tests
\end{itemize}

\section{Testability}

\begin{itemize}
  \item Search for JavaScript code to analyse, do representative selection for different areas of application
  \item Analyse testability of selected code segments by looking at how the applications are partitioned, how well single-purpose principles are followed, and what parts of the code is exposed and accessible by tests
  \item Discuss validity factors, whether the selection is fair and really representative, how open source affects quality, etc. (self-criticism)
\end{itemize}

\section{Framework evaluation}

\begin{itemize}
  \item Perform and document complexity of installation process
  \item Try different ``Getting Started'' instructions
  \item Compare syntax, functionality and dependencies
  \item Discuss suitable areas of application
  \item Create example implementations of different types of tests to illustrare practical use
\end{itemize}

\section{Adding tests to an existing project}

The current content of this section could be rewritten and placed in the method section, while replaced by actual results.

\begin{itemize}
  \item Identify what parts of the project are currently testable
  \item Identify what functionality should be tested
  \item Decide on testing framework and motivate choice based on circumstances and previous analysis
  \item Set up the testing environment so the tests can run automatically on a build server
  \item Write the actual tests and continually refactor the code, while documenting decisions in this report
  \item Analyse impact on code quality and number of bugs found
\end{itemize}

\section{The frameworks}

Programming languages in use today typically have frameworks to help with standard structure and other generic problems. JavaScript is certainly no exception, the number of web application frameworks that focus on JavaScript has increased a lot during the last few years alone.

A full evaluation of the most popular MVC and testing frameworks is not within the scope of this thesis, but others have done it. \cite{JackFranklin, SebastianPorto}

\section{Draft without title}

\subsection{Patterns}

Rather than proposing best practices for JavaScript testing, the reader should be made aware that different approaches are useful under different circumstances. This applies both to choice of tools and how to organise the tests.

\subsection{Why don't people test their JavaScript?}

Considering all the different options in available frameworks, one is easily deceived into believing that the main reason why people don't test their JavaScript is because they are lazy or uninformed. This is not necessarily true, there are respectable obstacles for doing TDD both in the process of fitting the frameworks into your application and in writing the JavaScript code in a testable way.

\subsection{JsTestDriver and Jasmine integration problems}

For instance, when setting up JsTestDriver (JSTD)\cite{JsTestDriver} with the Jasmine adapter there are pitfalls in which version you're using. At the time of writing, the latest version of the Jasmine JSTD adapter (1.1) is not compatible with the latest version of Jasmine (1.3.1), so in order to use it you need to find an older version of Jasmine (such as 1.0.1 or 1.1.0) or figure out how to modify the adapter to make it compatible. Moreover, the latest version of JSTD (1.3.5) does not support relative paths to parent folders when referencing script files in jsTestDriver.conf although a few older versions do (such as 1.3.3d), which is a problem if you want to place the test driver separate from the system under test rather than in a parent folder, or if you want to reference another framework such as Jasmine if it is placed in another directory.

\subsection{Testability, TDD, exposing code to tests, counter-intuitiveness of writing tests first}

Regardless whether or not the frameworks are effortlessly installed and configured or not, there is still the issue of testability. It is common to argue that TDD forces developers to write testable code which tends to be maintainable. This is true in some respects, but one has to bear in mind that JavaScript is commonly used with many side-effects that may not be easily tested. More importantly, it is common to place all the JavaScript code in a single file and hide the implementation using some variant of the module pattern\cite[p.~40]{GoodParts}, which means that only a small subset of the code is exposed as globally accessible functions, commonly functions that are called to initialize some global state such as event listeners. In order to test the functions, they need to be divided into parts, which will typically have to be more general in order to make sense as stand-alone modules. This conflicts with the eagerness of most developers to just get something that works without making it more complicated than necessary.

\subsection{Manual testing, psychology, refactoring}

The fundamental problem is probably that most developers are used to manually test their JavaScript in a browser. This gives an early feedback loop and although it does not come with the benefits of design, quality and automated testing that TDD does, it tends to give a feeling of not doing any extra work and getting the job done as fast as possible. Developers do not want to spend time on mocking dependencies when they are not sure that the solution they have in mind will even work. Once an implementation idea pops up, it can be tempting to just try it out rather than writing tests. If this approach is taken, it may feel like a superfluous task to add tests afterwards since that will typically require some refactoring in order to make the code testable. If the code seems to work good enough, the developer may not be willing to introduce this extra overhead. There is also a risk involved in refactoring untested code\cite[p.~17]{Refactoring}, since manually checking that the refactoring does not introduce bugs is time consuming and difficult to do well, although there is an exception when the refactoring is required in order to add tests. This is because leaving the code untested means even greater risk of bugs and the refactoring may be necessary in the future anyway, in which case it will be even harder and more error-prone.

\subsection{AngularJS, Jasmine and Karma}

The AngularJS framework uses Jasmine and Karma in the official tutorial.

\begin{quote}
``Since testing is such a critical part of software development, we make it easy to create tests in Angular so that developers are encouraged to write them''\cite{AngularTemplates}
\end{quote}

This is likely a large contributing factor for increasing the probability of Angular developers testing their JavaScript.

\subsection{Definitions}

A mock has pre-programmed expectations and built-in behaviour verification\cite[p.~453]{Tddjs}.

Because JavaScript has no notion of interfaces, it is easy to accidentally use the wrong method name or argument order when stubbing a function\cite[p.~471]{Tddjs}.

\section{Real world experiences}

\subsection{Testability issues with main.js in asteroids application}
\label{sec:asteroids}

Despite partitioning the JavaScript of the asteroids applications into separate classes, the problem of the canvas element not being available in the unit testing environment was not mitigated. The main.js file contained around 200 lines of code that could not be executed by tests without further refactoring since they were executed in a jQuery context (i.e. using \verbdef{\jquerycontext}{\$(function ()}\jquerycontext...) that included the selector \verbdef{\selector}{$("#canvas")}\selector. Efforts to load this code using ajax were of no gain, so the solution was instead to expose the contents of the context as a separate class and inject the canvas and other dependencies into that class. This required turning many local variables into attributes of the class to make them accessible from main.js such as the 2d-context.

The problem was not solved entirely through this approach though, since some parts could not be extracted. The event handling for key-presses necessarily remained in main.js and since that code could not be executed by unit tests, changes to global variables used in the event handler does not cause any unit test to fail, even though the application will crash when executed in an integration test. The problem could be solved just as before, by extracting the event handler code into a separate class that can be tested. The problem is that the event handler modifies local variables in main.js, which still can't be tested, so there has to be some test setup code to mock these when making them global, and this affects the design in a bad way by introducing even more global state.

Same goes with the main loop, which contains logic to draw grid boundaries. When refactoring main.js the main loop was left in main.js (which can not be tested) and this introduced a bug that was reproduced only when using the particular feature of displaying the grid. The feature is not important and could be removed. The bug could also be fixed by making a couple of variables globally accessible as attributes of the rendering class, but that too would introduce a code smell. A better solution was to move it into the rendering class, as it semantically belongs there.

As a consequence of being unable to extract all code from main.js into testable classes, I started to consider using selenium tests. This could actually be argued to be a sound usage of selenium because main.js is basically the most top level part of the application and as such can be more or less directly tested with decent coverage using integration tests. The Internet sources that I could find regarding how to use selenium with JavaScript depended on node.js and mocha, which I was inexperienced with using at the time. Consequently, I spent an afternoon trying to get things to work but without any real results. Posting on stack overflow asking for help could possibly have been a way forward instead of settling with manual testing.

One has to be careful when adding code to beforeEach, setUp and similiar constructs in testing frameworks. If it fails the result is unpredictable. At least when using Jasmine with JsTestDriver, not all tests fail even when the beforeEach causes failure, and subsequent test runs may produce false negatives even though the problem has been fixed. This is likely due to optimizations in the test driver and is especially apparent when the system under test is divided into multiple files and contain globally defined objects (rather than constructors). In this case, game.js contains such a globally defined object and its tests commonly fails after some other test has failed, even after passing the other test. Restarting the test driver and emptying the cache in the captured browser usually solves this problem, but is time demanding.

\subsection{JsTestDriver evaluation}

When resuming from sleep on a mac the server needs to be stopped and the browsers need to be manually re-captured to the server, or else the driver hangs when trying to run the tests. This is both annoying and time consuming. However, the problem is not present on a windows machine (and it might not be reproducable on all mac machines either). In the interview with Johannes Edelstam, he agreed that this is one example of something that deters people from testing\cite{Edelstam}.

Definitions are not cleared between test runs, meaning that some old definitions from a previous test run can remain and cause tests to pass although they should not because they are referring to objects that no longer exists or that tests can pass the first time they are run but then crash the second time although no change has been made to the code. Some of these problems indicate that the tests are bad, but it is inconvenient that the tool does not give you any indication when these problems occur, especially when there is false positives.

If there is a syntax error in a test, the JsTestDriver still reports that the tests pass. For example:

\begin{verbatim}
setting runnermode QUIET
...................................
Total 35 tests (Passed: 35; Fails: 0; Errors: 0) (23,00 ms)
  Chrome 27.0.1453.94 Windows: Run 36 tests (Passed: 35; Fails: 0;
Errors 1) (23,00 ms)
    error loading file: /test/sprites-spec/sprite-spec.js:101: Uncaught
SyntaxError: Unexpected token )
\end{verbatim}

As a developer, you might miss the ``error loading file'' message and that not all 36 tests were run, because the first line seems to say that everything went fine. Sometimes Jasmine does not run any test at all when there is a syntax error, but does not report the syntax error either. It is therefore recommended that you pay close attention to the terminal output and check that the correct number of tests were run rather than just that there was no failures. This is impractical when running the tests in a CI build because the build screen will typically display success even if no tests were run. It can be of help to keep a close look on the order in which files are loaded and also to keep the console of a browser open in order to be notified of syntax errors\cite{MikeJansen}.

Many of these problems can be said to stem from accidental integration tests or other errors in the tests. It should be noted however that proper stubbing of dependencies can be a daunting task, especially if dependency injection is not handled in a smooth way. In JavaScript, dependency injection can be argued to be harder than in for instance C or java because of the absence of class interfaces. The sinon.JS framework does simplify compared to manual stubbing (which on the other hand is exceptionally simple to do with JavaScript) but there is still issues of doing tradeoffs between dedicating many lines of code to stubbing, quite often having to repeat the same code in multiple places, or risk introducing bugs in the tests themselves. As a programmer you have to be very methodical, principled and meticulous not to miss some detail and write an accidental integration test. Such mistakes leave you with misleading failure result messages and sometimes the tests fail because of the order in which they are executed or similar, rather than because of an actual bug in the system under test.

Another source of problems is when global state is modified by constructors of different classes. For instance, when extracting code from main.js into rendering.js, part of that code was involved with initiating the grid which is shared between all the sprites in the application (through its prototype) and this meant the the grid was not defined unless the rendering class had been instantiated. This imposed a required order in which to run the tests and is an example of poor maintainability due to optimization.

Deficiencies such as these are important to note because they pose potential reasons to why JavaScript developers don't test their code. If using the tools and frameworks is perceived as cumbersome and demanding, fewer will use them and those who do will consider it worth doing so in fewer cases.

When a function is defined within a constructor it is hard to stub unless you have an object created by the constructor available. In some cases you don't because the system under test creates an instance by itself and then you are (as far as I know) out of options except for stubbing the entire constructor (this produces a lot of code in the tests) or changing the system under test to increase testability, for instance by having the instance passed as an argument (which allows for dependency injection but can be odd from a semantic point of view) or defining the functions that you need to stub on the prototype of the constructor instead of in the constructor (which allows for easy stubbing but is less reliable since another class/object can modify the function as well). Often it is possible to come up with a way that increases testability without having a negative impact on readability, performance, etc. of the system under test, but not always so. Regardless, this requires a skilled programmer and effort is spent on achieving testability rather than implementing functionality which may feel unsatisfactory.

JsTestDriver is not perfect. When refreshing and clearing the cache of a captured browser, you have to wait for a couple of seconds before running your tests or else the browser will hang and you have to restart the server. This wouldn't be such a problem if it wasn't because definitions from previous test runs remain in the browser between runs. For instance, if a method is stubbed in two different tests but only restored in the one that is run first, the tests will pass the first time they are run but then fail the second time. Realizing that this is what has happened is far from trivial so as a beginner you easily get frustrated with these small issues, since you might refresh the browser quite frequently in the process of finding out.

Having spent many hours debugging, I finally decided to do a thorough check that no test depended on another test or part of the application that is not supposed to be tested by a specific test. In short, I wanted to ensure that the tests I'd written were truly unit tests. In order to do this, I created a copy of the application repository, deleted every file in the copy except for one test and the corresponding part of the application. Then I configured a JSTD server with a browser to run only that test, and repeated the process for every test. This method does not guarantee absence of side effects or detecting tests that do not clean up after themselves, but being able to run a test multiple times without failing, in complete isolation with the part of the application that it is supposed to test, at least gives some degree of reassurance that all external dependencies have been stubbed. If any external dependency has been left unstubbed the only way for the test to pass is if the code exercising that dependency is not executed by the test, and if a test does not clean up after itself it is likely to fail the second time it runs although this too depends on how the tests are written.

\subsection{Testability and other issues with adding tests to an existing application}

Sometimes it can be hard to know whether or not to stub library functions such as \$.isFunction or if you should trust that they behave as expected and steer the control flow via their input and the global state instead. The same applies to simple functions you have written yourself that you think are free of bugs. Not stubbing external dependencies leads to fewer lines of test setup and teardown code and usually better test coverage but can also impose a danger of the unit tests becoming more brittle and similar to integration tests.

When adding tests to an existing application, it is easy to lose track of what has and what has not been tested. Having access to a functional specification of the application can be of help but it might be unavailable, incomplete or outdated. Then you have to make a specification of your own, in order to be systematic about what tests you write. This can be done top-down by looking at user stories (if there are any), talking with the product owner and the users (if any) or identify features to test through manual testing. It can also be done bottom-up by looking at the source code that is to be tested and come up with ideas regarding what it appears like all the functions should be doing. The latter is what was done before adding tests to the asteroids application because there was no documentation available and the application was so small that a bottom-up approach seemed feasible and likely to generate better coverage than doing a top-down specification. The way this was done was by writing test plans in the form of source code comments in the spec files for each class.

Each function was analyzed with respect to what was considered to be its expected behavior, such as adding something to a data structure or performing a call with a certain argument, and then a short sentence described that behavior so that it would not be forgotten when writing the actual tests later. Since tests are typically small, one might think that it could be a good idea to write the tests directly instead of taking the detour of writing a comment first, but my experience was that a comment is a lot faster to write than a complete test, makes up for fewer lines of code and avoids getting stuck with details about how to write the test.

Another useful method for knowing what tests to write was to write tests for every bug that was detected, i.e. regression testing. This should be done before fixing the bug so you can watch the test fail, which increases the chance that the test will fail if the same bug is introduced again. Additionally, some aspects of TDD can be employed even when the code lacks tests by writing tests that document any changes you make to the application. Be careful that you do not break existing functionality though, and that the tests focus on behavior rather than implementation details. The recommended approach is writing tests for the application in its existing form before starting to change it, since this will increase understanding of how it works and reduce risk of breaking existing functionality when refactoring later. These alternatives are still worth mentioning though, because sometimes code needs to be refactored in order to make it testable.

Traditionally, coverage criteria has been a central concept in software testing and is still today in many organizations (citation needed). When doing TDD however, the need for thinking in terms of coverage is reduced as every small addition of functionality is tested beforehand. There is no need to test specific implementation details because that will only make the system harder to change. If a certain function feels complex and likely to contain bugs, the recommended way in TDD is to take smaller steps, refactoring and testing new components separately rather than trying to achieve different kinds of graph and logic coverage for the complex function. When adding tests in retrospect it makes more sense to think about coverage, which may be done when the system is starting to feel complete in order to reduce risk of bugs. There are various tools available for ensuring that relevant parts of an application are exercised by tests and it is often relevant to design tests based on edge cases and abnormal use. As a tester, it tends to pays off having the attitude of trying to break stuff instead of just testing the so called happy flow. Different types of coverage criteria can help in formalizing this, as described in Introduction to Software Testing by Ammann and Offutt\cite{AmmannOffutt}.

To illustrate why achieving a certain coverage criteria should not be a goal in itself, I decided to write tests for the finite state machine (FSM) in the asteroids.Game object of the asteroids application. Achieving Clause Coverage\cite[p.~106]{AmmannOffutt} for 18 lines of production code (asteroids.Game.FSM.start) took almost 100 lines of test code, see commit 61713c of \url{https://github.com/emilwall/HTML5-Asteroids}. This is not that much, but it didn't provide much value either as no bug was found.

\subsection{Stubbing vs refactoring}

When an application is tightly coupled, stubbing becomes a daunting task. What you end up with is deciding whether you should compromise the unit tests by not stubbing everything, refactor the code to reduce the amount of calls that needs to be stubbed, or stub all dependencies. The first alternative bodes for unstable tests that might fail or cause other tests to fail for the wrong reasons. Refactoring might introduce new bugs and should probably only be done if it simplifies the design and makes the code more readable. Stubbing all dependencies might result in too much code or force you to complicate the testing configuration so that some code is run between each test. One case where this tradeoff had to be made was when writing tests for classes that depended on the Sprite class, such as the Ship class. It uses the Sprite class both for its ``exhaust'' attribute and for its prototype. Luckily, the Sprite constructor does not modify any global state, so in this case not stubbing the Sprite class before parsing the Ship class is acceptable. In the unit tests however, any calls to methods defined in Sprite are preferably stubbed, since they should be tested separately.

To detect improper stubbing, I ran each test isolated with just the file it was supposed to test. A problem with this was that trying to stub a function which is not defined produces an exception in order to prevent you from doing typos. This could be solved by saving the implementation in a local variable, defining the function to be an empty function, stub it with sinon.JS and then restore and re-set it to the original implementation, but this is inconvenient so instead I opted towards being careful not to miss any calls that should be stubbed. There is a point with interpreting the system under test before running any test code, since that allows for detection of typing mistakes and other integration issues.

\subsection{Deciding when and what to test}

Testing is especially important for large applications. It is extra valuable when new functionality is added because it helps to verify that old functionality is not broken and that the new code is structured appropriately. \cite[questions~6-7]{Stenmark}

You should focus on testing behaviour rather than appearance and implementation details. \cite[question~10]{Edelstam} Rather than testing that a certain class inherits from another, test that the methods of that class behaves as one would expect. Whether or not that is dependent on the inheritance patterns is mainly relevant for stubbing considerations - you may want to replace the prototype of an object in tests so that you can check that there are no unexpected dependencies. These are lessons learnt from working with the asteroids application, see section \ref{sec:asteroids}. 

Another thing that came up during the interview with Edelstam was that when something feels like it is hard to test, it is likely that any test you write will become rather brittle as the code changes in the future. The proposed solution was to avoid testing it unless the code can be refactored so that testing becomes easier. \cite[question~30]{Edelstam} When writing the tests for the asteroids application, I deliberately chose to write tests even when it felt hard or felt like it provided little value, to see whether this made the application harder to test later and if people would remove the bad tests during the workshop.

Because unit tests are typically fast, it is common practice to prioritise decent coverage and corner cases in the unit tests rather than in integration, UI, e2e (end to end) and other types of tests. When tests can be executed fast, they are more useful when changes are made to the code. This is especially important when someone other than the person who wrote the code is making the changes, or when some time has passed since the code was written. \cite[questions~22-24]{Stenmark}

Naturally, the more important a certain functionality is in relation to business value, the more effort should be put into e2e and similar tests related to it. Inherently complex parts of the code and code that is likely to change should be tested by unit tests to allow for refactoring and increase chance of discovering bugs, whereas simple code that is not expected to change can be tested manually. However, it is typically hard to know beforehand if the code you are writing is subject to change, so a compromise by writing a few simple tests for that code may pay off. \cite[question~28-29]{Stenmark}

\subsection{Meetup open space discussion}
\label{sec:openspace}

During a talk at a meetup on python APIs (2013-05-22 at Tictail's office, an e-commerce startup based in Stockholm), the speaker mentioned that their application depended heavily on JavaScript. It turned out that they had done some testing efforts but without any lasting results. During the open space after the talks, testing became a discussion subject in a group consisting of one of the developers of the application, among others. The developer explained that they had been unable to unit test their JavaScript because the functionality was so tightly coupled that the only observable output that they could possibly test was the appearance of the web page, via Selenium tests. He sought reassurance that they had done the right thing when deciding not to base their testing on Selenium due to instability (tests failing for the wrong reasons) and time required to run the tests. He also sought answers to how they should have proceeded.

The participants in the discussion were in agreement that testing appearance is the wrong way to go and that tests need to be fast and reliable. The experience with testing frameworks seemed to vary, some had used Jasmine and appreciated its behaviour driven approach and at least one had used Karma but under its former name Testacular. The idea that general JavaScript frameworks such as AngularJS could help in making code testable and incorporating tests as a natural part of the development was not frowned upon. The consensus seemed to be that in general, testing JavaScript is good if done right, but also difficult.

\subsection{Ideas spawned when talking about this thesis}

During my work on this thesis, I have explained to numerous people what it is that I'm doing. Typically, I've started out with saying something like ``I'm looking at testing of JavaScript''. Depending on if the person asking knows a lot about JavaScript or not, the conversation then might proceed in different directions, but the most common follow up is that I explain further that I'm looking at why people don't do it, when and how they should do it and what the problems and benefits are. Especially I'm looking at the problems.

One not so uncommon response is that testing of JavaScript probably is so uncommon because people programming in JavaScript often have a background as web graphic designers, without that much experience of automated testing. Another common conception is that JavaScript in practise is usually not testable because it has too much to do with the front-end parts of an application, so tests are inevitably slow, unmaintainable and/or unreliable because of the environment they have to run in.

\section{Interview summary}

It seems that in the last couple of years, the number of people testing their JavaScript has increased significantly\cite[question~1]{Edelstam}. This has been observed through asking people that do it to raise their hands during tech talks, two years ago only a few raised their hands when asked such a question whereas now almost every single one does it.

According to Edelstam, a likely reason for this change is that the tools have become better and that there are more examples of how to do it. This has caused the opinion that JavaScript is too user interface centered to recede, as people have realized how it can be done. Few people were ever against TDD or testing in general, much thanks to positive experiences from testing in Ruby on Rails projects, which actually act as great examples of that testing wide ranges of interfaces is possible and that many feel that it is necessary. Perhaps the most common reason for not testing is that the code has not been written in a testable fashion. \cite[questions~2-3]{Edelstam}

A common experience when writing tests is that you put a lot of effort into the tests and do not write that much production code in comparison, but that can be a good thing! Because then you spend more time thinking about the problem and possible abstractions, which tends to lead to elegant solutions. If you write the tests before the code, you will run into the same problems as you would have done if you wrote the code first, the difference is that you get to think about the design rather than staring at incomplete code when solving the problem. \cite[question~8]{Edelstam}

The feeling of being limited and not productive when writing tests can stem from a badly chosen level of ambition or that the focus of the tests is wrong, which in turn can be based on poor understanding of what tests are good for. Coding without tests can be much like multitasking, you get an illusion of being more productive than you actually are. One of the positive effects of TDD is that it can prevent you from losing track of direction, and helps you in making clear delimitations, since trying to be smart by allowing a function to do more than one thing means more tests. Testing will not automatically provide you with good ideas regarding where you are heading, but once you have gotten such an idea, testing tends to be easier and help you discover new aspects and scenarios which might would have been left unnoticed without tests. \cite[question~8]{Edelstam}

When deciding what to test, it pays off to focus on parts that are central to how the application is perceived, for instance pure logic and calculations might be more important than pictures and graphs. An error that propagates through the entire application is more serious than if a single picture is not displayed properly. If a test turns out to be difficult to write or frequently needs to be replaced by another test, it is usually worth considering not testing that part at all. \cite[questions~9-10]{Edelstam}

In June this year, Kent Beck wrote the following tweet\footnote{A tweet is a message sent to many using the social media \url{www.twitter.com}}:

\begin{quote}
``that was tough--it almost never takes me 6 hours to write one test. complicated domain required extensive research.''
\end{quote}

One of the responses was that many would have given up on writing that test. Beck replied that if you don't know how to write the test, you don't know how to write the code either\cite{TwitterKentBeck}. What many probably fail to realize about why testing can be time consuming and hard, is that when writing tests you encounter problems that you would have to solve anyway. The difference is that you solve the problems by formulating tests rather than staring at production code for the same amount of time. \cite[question~11]{Edelstam}

Tools are an important part of facilitating testing, so that people are not so deterred by the initial effort required to get started. Yeoman is one example of a framework that can help you in quickly getting started with a project that is structured so that testing becomes easier. For already existing projects, the increased maturity of tools such as PhantomJS and Mocha is also truly helpful. \cite[questions~11-12 and 20]{Edelstam}

Error reports are useful feedback that tests provide. The quality of these reports vary depending on which testing frameworks you are using and how you write your tests. When using PhantomJS to run tests, some test failures require you to run the tests in a browser in order to get good error reports. \cite[question~12]{Edelstam}

An important difference between using a headless browser such as PhantomJS to run your tests compared to JsTestDriver, or other drivers that allow you to test in several browsers, is that a headless browser provides no information about how your code performs on different JavaScript implementations. Reasons why you might still decide to do so include speed, easier integration with build tools such as Jenkins, and that it yields the same results as long as the tests focus on logic rather than compatibility. \cite[questions~13-15]{Edelstam}

% TODO: section: Ways of testing, selenium vs unit test in browser. headless vs real browser.

One could argue that JavaScript is better suited for testing than most other programming languages because of the built in features than often make stubbing frameworks redundant. The object literals can be used to define fake objects and it is easy to manually replace a function with another and then restore it. An advantage with using manually written fakes is that it tends to make the code easier to understand since knowledge about specific frameworks or DSLs (Domain Specific Language) is not required. \cite[questions~20-21]{Edelstam}\label{LiteralFakes}

The problems that some people experience with testing frontend interfaces sometimes have to do with poor modularity. For instance, the presentation layer should not be responsible for calling large APIs. Tools such as RequireJS can be used to handle dependencies but if each part of the application has too many or large dependencies, mocking becomes a daunting task. Typically, these kinds of problems can be solved by introducing new layers of logic and services that separate responsibilities and allows for much cleaner tests. \cite[question~23]{Edelstam}

A common case of user interface testing is form validation. Being test driven does not necessarily mean that you should test that the form exists, has a working submit button and other boilerplate things, unless the form is written in a way that is unique or new to you in some way. A typical approach would rather be to write the code for the form and then add a test that searches for a non-existing validation. The difficult part here is to strike a balance and be alert to when the code is getting so complicated that it is time to start testing, and to avoid writing tests when they are in the way and provide little value. \cite[questions~24-25]{Edelstam}

Being too religious about testing principles leads to conflicts like ``writing tests take too much time from the real job''. If the tests do not provide enough value for them to be worth the effort then they should be written differently or not at all. There is no value in writing tests just for the sake of it. Thinking about architecture and the end product is usually a good thing, because you need awareness of the bigger picture in order to prioritize correctly and make sure everything will fit together in the end. There is the same risk with tests as with other pieces of code, sometimes you are especially proud or fond of a certain test and unwilling to throw it away. In order to avoid that situation it is often better to think ahead and try things out than to immediately spend time writing tests. \cite[question~27]{Edelstam}

Writing implementation specific tests is a common phenomena that can stem from poor experience of writing tests, extreme testing ambitions or, perhaps most commonly, poor understanding of the system under test. It means that you write the tests based on details about the implementation that you have in mind rather than basing them on what the system should do from an interface point of view. These kind of tests should be avoided since they tend to be hard to understand and usually have to be changed whenever an improvement of the implementation is considered.

A large number of tests is not necessarily a good thing, it is harder to overview and maintain a large collection of tests. Unless the system inevitably is so complicated that extensive testing is justified, it rarely pays off to strive for 100 \% coverage, since it takes too much time and the scenarios that might cause problems are at risk of being overlooked anyway. \cite[question~28]{Edelstam}

Tests can serve to prevent people from breaking code and as examples that help new people understand how an application works and how to continue development \cite[questions~31-32]{Edelstam}. Tests also help to give a clear image of how components fit together and can be a way to concretize a feature or bug.

\subsection{Testing private APIs}

Most problems with APIs, both external and private, are similar to problems with any external dependencies that you do not have full control over. The tests need to be kept up to date and in order to do so, integration tests are needed. Sometimes, testing towards a true implementation is problematic because it takes too long time, manipulates data that should not be touched or because the owner of the API does not accept large amounts of traffic or requires payment for it. Then you typically run the integration tests less often and stick to mocked APIs with fake objects to compensate. \cite[questions~19-20]{Stenmark}

Testing private APIs differs from testing calls to an external API in that the latter are often well documented, versioned and rarely changes. When using an external API, the main concerns are making sure that the correct version is used and that the API is called in a correct way with respect to that version. A private API on the other hand may change frequently which means that the fake objects representing requests and responses of the API in other tests need to change as well. Private APIs need to be tested because endpoints frequently change and may be used in several places. It is then important to have integration tests that can detect when the fakes need to change. \cite[questions~34,~36]{Edelstam}

Introducing versioning for private APIs is not always feasible, for at least two reasons. There can be difficulties in keeping track of the different versions and there can be a risk of hampering development since the parts that use the API are dependent on the new version of the API to be released before they can be updated. However, there exists testing techniques that can be employed regardless if versioning is in place or not. One such technique is to write tests for what characterizes an object that the API serves as an interface for, to be able to determine if an object is a valid response or request. These tests can then be used on both real objects and on the fake objects that are used in other tests, which means that when the API changes the tests can be updated accordingly and then the tests involving the fake will fail. Changing the fakes so that the tests passes will hopefully result in that any incompatibility is discovered since the fakes are used in other parts of the testing suite as well. \cite[question~34]{Edelstam}

Testing a private API is not the same thing as testing a private method. In JavaScript there is formally no private methods, only functions not exposed to the current scope, nevertheless methods that are not intended to be called from the outside can be considered private. It is a common principle that you do not test a private method, if you feel the need to, then that method is probably too complex to be private and the functionality that it is meant to provide should be moved into a new object or similar. Private methods represent implementation details, tests should be focused on behaviour and functionality, not implementation. \cite[questions~62-63]{Edelstam}

\subsection{Culture, Collaboration and Consensus}
\label{sec:ccc}

Testing is not about eliminating the risk of bugs or ensuring that every line of code is executed exactly the way it was originally meant to be executed. In order to better understand the main benefits of testing, it is recommended to read books such as Clean Code, and to work together with experienced programmers and testers. Without this understanding there is a risk of frustration, inability to decide which tools to use and difficulties in motivating choices related to testing. Collaboration problems may occur when members of a team have different opinions about the purpose of testing. \cite[question~38]{Edelstam}

To get as much benefit as possible from testing, every developer should be involved in the testing effort and preferably the product owner and other stakeholders too. The work of specifying stories can involve agreeing on testing scenarios, thinking about what the desired behavior is and coming up with examples that can be used as input and expected output in end-to-end tests. \cite[questions~39-40]{Edelstam}

\subsection{Frameworks and tools}

There are a number of BDD frameworks available that are meant to bring testing closer to the specification and story work, as proposed in section~\ref{sec:ccc}. They aim to mimic the way stories are written to create a ubiquitous natural language that can be understood by both programmers and non-programmers. The way this is done is by building sentences with a Given, Then, When (GTW) form. Cucumber is a popular framework that was designed for this in the Ruby programming language and there is a JavaScript version called Cucumber.js. Yadda, Kyuri, Cucumis and Jasmine-given are other examples of JavaScript GTW-frameworks. \cite[section 8.4]{BDDJS}\cite{Cucumis}

Apart from testing frameworks, your ability to write tests is also influenced by what application framework you are using. According to Edelstam, if you are able to choose, it is often preferable to have small rather than ``magic bullet'' frameworks for large projects because they tend to be less obtrusive. Exceptions may include when the framework is very well known to the developers or when there is a perfect fit between what you want to achieve and what the framework is designed for, but one should bear in mind that requirements tend to evolve. \cite[questions~48-50]{Edelstam} Stenmark had another view on things and instead recommended small frameworks only for small projects, since the value of bindings and other features tend to outweigh adjustment problems. \cite[questions~12-14]{Stenmark}

Using a suitable application framework and doing test driven development can be mutually beneficial. The framework helps to create structure that simplifies testing and the testing process further improves the quality of the code, allowing you to make better use of the framework and providing incentive for even better structure. \cite[question~15]{Stenmark}

\subsection{Testability and Selenium}

As mentioned in section~\ref{sec:browserautomation}, Selenium is currently the most popular tool for browser automation. Sometimes it is the only way to test the JavaScript of an application without rewriting the code (as mentioned in section\ref{sec:openspace}) but then tests tend to be brittle and provide little value. In general, since Selenium tests take such time to run they should only cover the most basic functionality in a smoke test fashion. \cite[questions~16-17]{Stenmark} Testing all possible interaction sequences is rarely feasible and should primarily be considered if it can be done fast, such as in a single page application (SPA) where sequences can be tested without reloading the page. \cite[question~44]{Edelstam}

With Selenium IDE (see section~\ref{sec:browserautomation}), there is a possibility of recording a certain interaction and generate code for it. This could potentially be used to reproduce bugs by letting the user that encountered the bug record the actions that led to it, and communicate with a developer so that proper assertions are added at the end of the sequence. This has some interesting implications, but experience shows that it is hard to do it in practice since it requires the users to be trained in how to use the plugin and to invest extra time whenever an error occurs. \cite[questions~42-43]{Edelstam}

\subsection{Build tools} % Technical background

There exists some general build tools that can be used for any programming language, these are often installed on build servers and integrated with version control systems. Examples include Jenkins, which is often configured and controlled through its web interface although it also has a CLI, and GNU Make, which is typically configured using makefiles and controlled through CLI. In addition to these, there are also language specific tools: Ruby has Rake, Java has Maven, Gradle and Ant, C\nolinebreak\hspace{-.05em}\raisebox{.3ex}{\scriptsize\bf \#} has MSBuild and NAnt.

Naturally, there are build tools designed specifically for JavaScript as well, Grunt being the most popular, which can be installed as a node.js package, has plugins for common tasks such as lint, testing and minification, and can be invoked through CLI. \cite{Grunt}\cite[question~52]{Edelstam} Jake and Mimosa are other well known and maintained alternatives. It is also possible to use Rake, Ant or similar. \cite{BuildTools}

\subsection{Stubbing and Mocking} % Technical background

In JavaScript, tools for stubbing can be superfluous because you are able to manually replace functions with custom anonymous functions, that can have attributes for call assertion purposes. The stubbed functions can be stored in local variables in the tests and restored during teardown. This is what some refer to as VanillaJS \cite[question~53]{Edelstam}. It might come across as manual work that you can avoid by using a stubbing tool, but the benefits include fewer dependencies and sometimes more readable code, as mentioned in section \ref{LiteralFakes}. \cite[questions~54-55]{Edelstam}

Typical cases for using a stubbing or mocking framework rather than VanillaJS include when your assertion framework has support for it, as is the case for Jasmine, when you feel the need to do a complex call assertion, mock a large API or state expectations up front as is done with mocks. Bear in mind that this might be a symptom for that the code is in need of refactoring though, and strive for consistency by using a single method for stubbing -- mixing VanillaJS with Jasmine spies and sinonJS stubs will make the tests harder to understand.

\subsection{Patterns, Examples and Documentation}

Examples are useful when learning idiomatic ways of solving problems. Code tends to end up being more complicated than examples you read because it is hard to come up with useful abstractions that make sense. Those who write examples to illustrate a concept always have to find a tradeoff between simplicity, generality and usefulness, and tend to go for simplicity \cite[questions~56-57]{Edelstam}. Combining different concepts may help to achieve code with good separation, that can be tested by simple tests. Today blog posts and books about patterns in JavaScript are in abundance and you can often find examples in the documentation of frameworks. When it comes to examples of testing in general there are several classics to refer to \cite{KentBeck}\cite{TestPatterns}. For examples of JavaScript testing specifically the alternatives are scarce but they do exist \cite{Tddjs}\cite{BDDJS}\cite{TestableJS}.

\subsection{Spikes in TDD}

Although writing tests first is a recommended approach in most situations, there is a technique for when you need to try something out before you write tests for it, without compromising testability. Dan North, the originator of BDD, came up with a name for this technique: spiking \cite{TwitterDanNorth}. The idea is that you create a new branch in your version control repository, and hack away. Add anything you think might solve your problem, don't care about maintainability, testability or anything of the sort. If you find yourself not knowing how to proceed, discard all changes in the branch and start over. As soon as you get an idea about how a solution could look like you switch back to the previous branch and start coding in a test first fashion. \cite[question~59]{Edelstam}

There is an ongoing discussion about whether or not you have to start over after a spike. Liz Keogh, a well known consultant and core member of the BDD community, has published posts about the subject in her blog, in which she argues that an experienced developer can benefit from trying things out without tests (spiking) and then stabilizing (refactoring and adding tests) once sufficient feedback has been obtained to reduce the uncertainty that led to the need for spiking \cite{Liz1}. She argues that this allows her to get faster feedback and be more agile without compromising the end result in any noticeable way. In another post, she emphasizes that this approach is only suitable for developers who are really good at TDD, while at the same time claiming that it is more important to be ``able to tidy up the code'' than ``getting it right in the first place'' \cite{Liz2}. It may seem like an elitist point of view and a sacrilege towards TDD principles but in the end, whatever makes you most productive and produces the most valuable software has raison d'tre.

Counterintuitive it may seem, throwing away a prototype and starting from scratch to test drive the same feature can improve efficiency in the long run. The hard part of coding is not typing, it is learning and problem solving. A spike should be short and incomplete, its main purpose is to help you get your mind set on what tests you can write and what the main points in a solution would be. \cite[question~60]{Edelstam}

\subsection{The DRY principle in testing}

The point of the Don't Repeat Yourself (DRY) principle is \emph{not} that the same lines of code cannot occur twice in a project, but that the same \emph{functionality} must not occur twice. Two bits of code may seem to do the same thing while in reality they don't. This applies to eliminating duplication both in production code and tests, do not overdo it since that will harm maintainability rather than improve it. Sometimes it is beneficial to allow for some duplication up front and then refactor once you have a clear picture about how alike the two scenarios actually are, if necessary. \cite[questions~69-70]{Edelstam}

\subsection{Impact of Node.js on testing}

Aside from the increased awareness and knowledge of testing that Node.js has brought to the JavaScript community from other communities such as Ruby on Rails, the runtime itself facilitates testing since it enables different testing tools to be distributed through npn and run in the terminal. Previously, you had to load a html page in a browser in order to run your tests. \cite[question~9]{Stenmark}

\subsection{The JavaScript Community}

In order to understand the problems with testability that can be seen in JavaScript applications, it is important to understand how many were first introduced to the language. When jQuery was released in 2006, a coding style evolved based on handlers with DOM manipulation through selectors and asynchronous callbacks. Since tutorials were written in a quick-and-dirty fashion, even experienced developers failed to apply principles for writing testable and maintainable code. Others lacked the background of software engineering altogether. \cite[question~10]{Stenmark}

\subsection{Tests that depend on the DOM}

Tests that depend on the DOM (see section \ref{sec:dom}) tend to be relatively slow. Therefore, it would be impractical to base every unit test on DOM manipulation, at least for large applications. \cite[questions~21-22]{Stenmark}

\printbibliography

\end{document}
