% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode
% arara: pdflatex: { draft: true }
% arara: biber
% arara: pdflatex: { synctex: true }
% arara: pdflatex: { synctex: true }

\documentclass[11pt]{article}

\usepackage[swedish,english]{babel} % Enables swedish typesetting, needs to be at top of document
\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX
\usepackage{textcomp} % Suppress unicode char error
\usepackage{enumitem} % resume numbering in enumerations
\usepackage[bottom = 110pt]{geometry} % to change the page dimensions
\geometry{a4paper} % paper format, could also be placed in documentclass options
\usepackage{graphicx} % support the \includegraphics command and options
\usepackage[parfill]{parskip} % Begin paragraphs with an empty line rather than an indent
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{verbdef} % inline verbatim
%\usepackage{titling} % required for setlength droptitle (below)
%\setlength{\droptitle}{-70pt} % Adjust title height
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{} % fancyhdr style reset for header
\lfoot{}\cfoot{\thepage}\rfoot{} % fancyhdr style reset for footer
\usepackage{sectsty} % Section title
\allsectionsfont{\sffamily\mdseries\upshape} % Section font
\usepackage{hyperref} % href
\usepackage{nameref} % Enable referring to the actual name of the chapter
\usepackage[backend=biber,sorting=none]{biblatex}
\bibliography{references.bib}
\usepackage{url}

\title{How to test your JavaScript}
\author{Emil Wall}
%\date{} % Uncomment to hide date, or provide a date to display

\begin{document}
\pagenumbering{gobble} % Turn off page numbering

\maketitle

\vspace{100pt}
The final version will have title page and endpaper generated from \\
\url{http://pdf.teknik.uu.se/pdf/exjobbsframsida.php} and \\
\url{http://pdf.teknik.uu.se/pdf/abstract.php}. \\
Hence, this page and the abstract are temporary, to be replaced in the final version.

\newpage
\clearpage\mbox{}\clearpage
\newpage

\begin{abstract}
Abstract goes here... Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam sollicitudin varius libero ac consectetur. Nullam ornare, massa et sagittis consectetur, neque mi scelerisque arcu, in fringilla lectus risus non arcu. Suspendisse vestibulum tellus id mauris lacinia non hendrerit nibh tempor. Proin tempor interdum justo et elementum. Ut ultricies adipiscing ipsum et pharetra. Vestibulum pretium luctus est, quis egestas augue luctus et. Praesent volutpat pharetra lectus vitae elementum.

Integer fringilla ligula eu sem semper tincidunt. Nullam mi lacus, blandit non sollicitudin eget, tempor eu ante. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Morbi ornare sem et purus consequat ac adipiscing nunc tincidunt. Curabitur nisi ante, ornare vel adipiscing et, scelerisque vitae erat. Etiam blandit egestas magna, quis dapibus nulla euismod quis. Sed interdum interdum malesuada. Suspendisse lacinia imperdiet laoreet. Maecenas ullamcorper laoreet nunc ac egestas. Cras consequat elit eu lacus sollicitudin ut pharetra magna venenatis. Suspendisse scelerisque condimentum pulvinar. Mauris ut tellus sit amet nulla porttitor tristique. Suspendisse eleifend erat sed nisi lacinia eu lacinia metus porta. Nulla pretium, risus eget semper laoreet, dolor odio malesuada eros, at mattis enim turpis gravida felis. Aliquam adipiscing varius nibh, ac auctor eros bibendum non.
\end{abstract}

\newpage
\clearpage\mbox{}\clearpage
\newpage

\section*{Acknowledgment}

Thanks goes to my supervisor Jimmy Larsson for providing me with valuable feedback and connections, to my reviewer Roland Bol for guiding me through the process and giving useful and constructive comments on my work, to all my wonderful colleagues at Valtech which never fails to surprise me with their helpfulness and expertise, to my girlfriend Matilda Kant for her endurance and support and to my family and friends (and cats!) for all the little things that ultimately matters the most.

\newpage
\clearpage\mbox{}\clearpage
\newpage

\tableofcontents

\newpage
\clearpage\mbox{}\clearpage
\newpage

\pagenumbering{arabic} % Turn page numbering back on

\section{Introduction}

The testing community around JavaScript still has some ground to cover. The differences in testing ambitions becomes especially clear when compared to other programming communities such as Ruby and Java. As illustrated by Mark Bates\cite{TestingStatistics}:

\begin{quote}
``Around the beginning of 2012, I gave a presentation for the Boston Ruby Group, in which I asked the crowd of 100 people a few questions. I began, `Who here writes Ruby?' The entire audience raised their hands. Next I asked, `Who tests their Ruby?' Again, everyone raised their hands. ``Who writes JavaScript or CoffeeScript?' Once more, 100 hands rose. My final question: `Who tests their JavaScript or CoffeeScript?' A hush fell over the crowd as a mere six hands rose. Of 100 people in that room, 94\% wrote in those languages, but didn't test their code. That number saddened me, but it didn't surprise me.''
\end{quote}

JavaScript is a scripting language primarily used in web browsers to perform client-side actions not feasible through plain HTML and CSS. Due to the dynamic nature of the language, there is typically little static analysis performed on JavaScript code compared to code written in a statically typed compiled language. Granted, there are tools available such as JSLint, JavaScript Lint, JSure, the Closure compiler, JSHint and PHP CodeSniffer. JSLint is perhaps the most popular of these and does provide some help to avoid common programming mistakes, but does not perform flow analysis\cite{JSLint} and type checking as a fully featured compiler would do, rendering proper testing routines the appropriate measure against programming mistakes. After all, there are benefits of testing code in general, for reasons that we will come back to, but JavaScript is particularly important to test properly due to its dynamic properties and poor object orientation support. Despite the wide variety of testing frameworks that exists for JavaScript, it is generally considered that few developers use them. The potential risk of economic loss associated with untested code being put into production, due to undetected bugs, shortened product lifetime and increased costs in conjunction with further development and maintenance, constitutes the main motivation for this thesis.

\subsection{Motivation}

JavaScript code is presumably becoming increasingly commonly used as part of business critical operations, considering that more than 90 \% of today's websites use JavaScript\cite{BusinessJavascript} and it may be assumed to be especially prevalent in sites with a lot of content and functionality. The economic risk of having untested JavaScript is especially high when the code is connected to critical operations. For instance, application failure for a webshop may cause loss of orders and any web site that is perceived as broken can harm trademarks associated with it and change people's attitude for the worse. Moreover, when automatic regression tests are missing, making changes to the code is error prone. Issues related to browser compatibility or subtle dependencies between functions and events are easily overlooked instead of being detected by tests prior to setting the site into production. Manually testing a web page with all the targeted combination of browsers, versions and system platforms is not a viable option\cite{TestSwarm} so multi-platform automated testing is required.

High quality tests are maintainable and test the right thing. If these conditions are not met, responding to changes is harder, and the tests will tend to cause frustration among the developers instead of detecting bugs and driving the understanding and development of the software\cite{Clean}. The criteria for maintainability in this context are that the tests should have low complexity (typically short test methods without any control flow), consist of readable code, use informative variable names, have reasonably low level of repeated code (this can be accomplished through using Test Utility Methods\cite[599]{TestPatterns}), be based on interfaces rather than a specific implementation and have meaningful comments (if any). Structuring the code according to a testing pattern such as the Arrange-Act-Assert\cite{C2} and writing the code so that it reads like sentences can help in making the code more readable, in essence by honouring the communicate intent principle\cite[p.~41]{TestPatterns}. Testing the right thing means focusing on the behaviour that provides true business value rather than trying to fulfill some coverage criteria, testing that the specification is fulfilled rather than a specific implementation and to find a balance in the amount of testing performed in relation to the size of the system under test. Typically some parts of the system will be more complex and require more rigorous testing but there should be some level of consistency in the level of ambition regarding testing across the entire application. Specifically, if some part of the code is hard to test it is likely to be beneficial in the long run to refactor the design to provide better testability than to leave the code untested.

Unit testing is particularly powerful when run in combination with integration test in a CI build\footnote{Continuous Integration build servers are used for automatic production launch}. Then you are able to harness the power of CI, avoiding errors otherwise easily introduced as changes propagate and affect other parts of the system in an unexpected way. This will make developers changing parts of the system that the JavaScript depends upon aware if they are breaking previous functionality.

Testing JavaScript paves the way for test-driven development, which brings benefits in terms of the design becoming more refined and increased maintainability. Tests can serve as documentation for the code and forcing it to be written in a testable manner, which in itself tends to mean adherence to key principles such as separation of concerns, and single responsibility.

The goal with this thesis is to investigate why JavaScript testing is performed to such a small extent today, and what potential implications an increased amount of testing could provide for development and business value to customers. Providing possible approaches to testing JavaScript under different conditions are also part of the goal.

\subsection{Background to project}

Writing tests for JavaScript is nothing new, the first known testing framework JsUnit was created in 2001 by Edward Hieatt\cite{GoingFaster,JsUnitGithub} and since then several other test framework has appeared such as QUnit \cite{QUnitSite} and JsUnits sequel Jasmine \cite{JasmineSite}, as well as tools for mocking\footnote{mocking and stubbing involves simulation of behavior of real objects in order to isolate the system under test from external dependencies} such as Sinon.JS\cite{SinonJS}. It seems as if the knowledge of how to smoothly get started, how to avoid making the tests non-deterministic and time consuming, and what to test, is rare. Setting up the structure needed to write tests is a threshold that most JavaScript programmers do not overcome\cite{TestingStatistics} and thus, they lose the benefits, both short and long term, otherwise provided by testing.

In guides on how to use different JavaScript testing frameworks, examples are often decoupled from the typical use of JavaScript - the Web. They tend to merely illustrate testing of functions without side effects and dependencies. Under these circumstances, the testing is trivial and most JavaScript programmers would certainly be able to put up a test environment for such simple code. In contrast, the problem domain of this thesis is to focus on how to test the behaviour of JavaScript that manipulates DOM elements (Document Object Model, the elements that html code consists of), interacts with databases and fetches data using asynchronous calls, as well as when and why you should do it.

\section{Description of Work}

Researching today's limited testing of JavaScript may be done from a multiple different points of view. There are soft aspects such as:
\begin{itemize}
\item Differences in attitudes towards testing between different communities and professional groups
\item How JavaScript is typically conceived as a language and how it is used
\item Knowledge about testing among JavaScript developers
\item Economic viability and risk awareness
\end{itemize}

There are also more technical aspects:
\begin{itemize}
\item Testability of JavaScript code written without tests in mind
\item Usability of testing tools and frameworks
\item Reasons not to include frameworks in a project for the sole purpose of facilitating testing
\item Limitations in what can be tested
\item Complexity in setting up the test environment; installing frameworks, configuring build server, exposing functions to testing but not to users in production, etc.
\end{itemize}

\subsection{Consequences of JavaScript testing}

There are consequences (good and bad) of testing JavaScript both from a short and from a longer perspective. The development process is affected; through time spent thinking about and writing tests, shorter feedback loops, executable documentation and new ways of communicating requirements with customers. The business value of the end result is also likely to be affected, as well as the quality and maintainability of the code. Ideally, the pace of development does not stagnate and making changes becomes easier when the application is supported by a rigorous set of tests. The extra time required to set up the test environment and write the actual tests may or may not turn out to pay off, depending on how the application will be used and maintained.

\subsection{Covering common and advanced cases}

Accounting for how to conveniently proceed with JavaScript testing should cover not only the simplest cases but also the most common and the hardest ones, preferably while also providing evaluation and introduction to available tools and frameworks. Many introductions and tutorials found for the testing frameworks today tends to focus on the simple cases of testing, possibly because making an impression that the framework is simple to use has been more highly prioritised than covering different edge cases of how it can be used that might not be relevant to that many anyway. To provide valuable guidance in how to set up a testing environment and how to write the tests, attention must be paid to the varying needs of different kinds of applications. It is also important to keep in mind that the tests should be as maintainable as the system under test, to minimise maintenance costs and maximise gain.

\section{Technical background}

This section gives an overview of concepts and tools relevant to understanding this thesis. Readers with significant prior knowledge about JavaScript testing may skip this section.

\subsection{Browser Automation}

Repetitive manual navigation of a web site is generally boring and time consuming. There are situations where manual testing is the right thing to do, such as when there is no need for regression testing or the functionality is too complicated to interact with for automated tests to be possible (but then the design should probably be improved). Most of the time, tasks can be automated. There are several tools available for automating a web browser: the popular open source Selenium WebDriver, the versatile but proprietary and windows specific TestComplete and Ranorex, the Ruby library Watir and its .NET counterpart WatiN, and others such as Sahi and Windmill.

\section{Methods}

The methods used are first and foremost qualitative in nature, in order to prioritise insight into the problem domain above quantitatively verifying hypotheses. The chance of finding out the true reasons to why JavaScript is tested to such a small extent increases with open questions. Specifically, aside from literature studies, the main method of this thesis work has been to perform and analyse interviews of JavaScript programmers (mainly those concerned with user interface). There has also been some hands on evaluation of tools and frameworks, and assessment of testability and impact of adding tests to existing projects. In order to describe methods of writing tests for JavaScript, the practical work involved testing an existing application, performing TDD as described in Test-driven JavaScript Development\cite{Tddjs} and doing some small TDD projects during the framework evaluation. Another method used was a workshop field study, where programmers were allowed to work in pairs to solve pre-defined problems using TDD.

The following testing frameworks have been evaluated: Jasmine\cite{JasmineSite} (+ Jasmine-species\cite{JasmineSpecies}), qUnit\cite{QUnitSite}, Karma\cite{KarmaSite}, Mocha\cite{MochaSite}, JsTestDriver\cite{JsTestDriver}, Buster.JS\cite{BusterJS} and Sinon.JS\cite{SinonJS}. The code written while evaluating the frameworks is publicly available as git repositories under my github account \emph{emilwall}, together with the \LaTeX~code for this report.

Semi-structured interviews were used rather than surveys to gather individual views on the subject. This approach allowed for harnessing unique as well as common experiences which would not be picked up in a standardised survey.

\subsection{Interview Considerations}

The preparations before the interviews where included specifying purpose and which subjects to include, select interviewees, put together questions and other material and adjust the material to fit each interviewee. The interviews took place rather late to ensure that the interviewer could obtain a solid background and domain knowledge. Each interview was summarised in writing and the collected material was structures and analysed to increase conciseness of results.

\subsection{Interview Questions}

\subsubsection{Formalities}
The interviews took place in calm, undisturbed locations, and began with a short recap on the background and purpose of the interviews. The interviewee was informed that the purpose of the interview was to gain a better understanding of different aspects of JavaScript testing. What problems and benefits exists and how it is connected with other software engineering practices and tools.

\begin{itemize}
\item Is it ok if I record our conversation?
\item Do you want to be anonymous?
\end{itemize}

\subsubsection{The interviewee}
\begin{itemize}
\item What kind of applications do you typically develop with JavaScript?
\item What tools and frameworks have you used? What roles have they played in your development processes?
\item Which are your favourites among the frameworks? Why?
\end{itemize}

\subsubsection{JavaScript in general}
\begin{itemize}
\item How productive do you feel when coding in JavaScript compared to other languages?
\item How do you typically perceive JavaScript code written by others?
\item What advanced features of JavaScript do you use, such as prototypal inheritance, dynamic typing and closures?
\item How do you think the JavaScript syntax and features impacts maintainability?
\item How would you assess the probability of making mistakes while coding in JavaScript?
\end{itemize}

\subsubsection{JavaScript testing experience}
\begin{itemize}
\item What is your experience with unit testing of JavaScript?
\item What is your experience with UI testing?
\item What is your experience with integration and end-to-end tests?
\item Have you practiced test driven development with JavaScript? To what extent? Has this been helpful? (if not, why? what did you do instead?)
\item Have you used any mocking and stubbing tools? Which, and what has been your experience with these?
\end{itemize}

\subsubsection{Challenges in testing}
\begin{itemize}
\item How do you go about determining what to test?
\item What principles do you apply when writing the tests? (short test methods, avoiding control flow, code duplication)
\item Have you ever set up a testing environment? If so, did you find it hard? If not, do you imagine it to be difficult?
\end{itemize}

\subsubsection{Benefits of testing}
\begin{itemize}
\item In your opinion, what are the main benefits from testing your JavaScript?
\item When do you think testing JavaScript pays off?
\item Have you ever had tests that impaired your productivity by being too hard to change or even understand?
\item Has tests helped you in debugging and quickly finding the source of a bug?
\item Has testing helped you discover bugs in the first place? Has this saved you from trouble further on?
\item Has testing helped your design?
\item What role has JavaScript testing played in any continuous integration you've had?
\item What type of JavaScript coding do you think is best suited for TDD?
\end{itemize}

\subsubsection{Adding tests to existing application}
\begin{itemize}
\item Have you ever been given the task of adding tests to an existing (JavaScript) application?
\item Was this hard?
\item What changes in the application were required in order to be able to write the tests?
\item Did you feel safe in changing the application or were you afraid that you'd might introduce new bugs?
\end{itemize}

\section{Previous work and Delimitations}

There exists academic papers on testing web applications and a few focus on JavaScript specifically. Some focus on automatically generating tests\cite{AutomatedTesting} and although useful for meeting code coverage criteria, these methods will not be discussed to any great length here since such tests are hard to maintain and likely to cause false positives when refactoring code. In this thesis, there will be more focus on how to employ test driven development than achieving various degrees of code coverage.

Heidegger et al. cover unit testing of JavaScript that manipulates the DOM of a web page\cite{DOMJavascript} and Ocariza et al. have investigated frequency of bugs in live web pages and applications\cite{Wild}. These are of more interest to this thesis since they are aimed at testing of client side JavaScript that runs as part of web sites.

The main source of reference within the field of JavaScript testing today is Test-Driven JavaScript Development\cite{Tddjs} by Christian Johansen which deals with JavaScript testing from a TDD perspective. Johansen is the creator of Sinon.JS\cite{SinonJS} and a contributor to a number of testing frameworks hosted in the open source community.

The scope of this thesis has been to look mainly at testing of \emph{client side} JavaScript. This meant that framework specialised for server side code such as vows\cite{Vows} and cucumis\cite{Cucumis} are not included in the evaluation part. Testing client side code is by no means more important than the server side, but it can be argued that it is often harder and the parallels to testing in other languages are somewhat fewer since the architecture typically is different.

Frameworks that are no longer maintained such as JsUnit\cite{JsUnitGithub} and JSpec\cite{JSpec} have deliberately been left out of the evaluation. Others have been left out because of fewer users or lack of unique functionality; among these we find TestSwarm, YUI Yeti and RhinoUnit. They are still useful tools that can be considered but including them would have a negative impact on the rest of the evaluation work because of the extra time consuming activities that would be imposed.

\section{Analysis of Economic Impacts}

\begin{itemize}
  \item Identify cases where companies and authorities have suffered economic loss due to bugs in JavaScript code vital to business critical functions of web sites
  \item Assess risks and undocumented cases of manifested bugs
  \item Estimate maintenance costs of code that lack tests compared to well-tested code
  \item Draw conclusions about how test-driven development can either shorten or prolong the time required to develop a product, depending on programmer experience and the size and type of the application being developed
  \item Costs associated with acquiring developers with the skills necessary to write tests
\end{itemize}

\section{Testability}

\begin{itemize}
  \item Search for JavaScript code to analyse, do representative selection for different areas of application
  \item Analyse testability of selected code segments by looking at how the applications are partitioned, how well single-purpose principles are followed, and what parts of the code is exposed and accessible by tests
  \item Discuss validity factors, whether the selection is fair and really representative, how open source affects quality, etc. (self-criticism)
\end{itemize}

\section{Framework evaluation}

\begin{itemize}
  \item Perform and document complexity of installation process
  \item Try different ``Getting Started'' instructions
  \item Compare syntax, functionality and dependencies
  \item Discuss suitable areas of application
  \item Create example implementations of different types of tests to illustrare practical use
\end{itemize}

\section{Adding tests to an existing project}

The current content of this section could be rewritten and placed in the method section, while replaced by actual results.

\begin{itemize}
  \item Identify what parts of the project are currently testable
  \item Identify what functionality should be tested
  \item Decide on testing framework and motivate choice based on circumstances and previous analysis
  \item Set up the testing environment so the tests can run automatically on a build server
  \item Write the actual tests and continually refactor the code, while documenting decisions in this report
  \item Analyse impact on code quality and number of bugs found
\end{itemize}

\section{Draft without title}

\subsection{Patterns}

Rather than proposing best practices for JavaScript testing, the reader should be made aware that different approaches are useful under different circumstances. This applies both to choice of tools and how to organise the tests.

\subsection{Why don't people test their JavaScript?}

Considering all the different options in available frameworks, one is easily deceived into believing that the main reason why people don't test their JavaScript is because they are lazy or uninformed. This is not necessarily true, there are respectable obstacles for doing TDD both in the process of fitting the frameworks into your application and in writing the JavaScript code in a testable way.

\subsection{JsTestDriver and Jasmine integration problems}

For instance, when setting up JsTestDriver (JSTD)\cite{JsTestDriver} with the Jasmine adapter there are pitfalls in which version you're using. At the time of writing, the latest version of the Jasmine JSTD adapter (1.1) is not compatible with the latest version of Jasmine (1.3.1), so in order to use it you need to find an older version of Jasmine (such as 1.0.1 or 1.1.0) or figure out how to modify the adapter to make it compatible. Moreover, the latest version of JSTD (1.3.5) does not support relative paths to parent folders when referencing script files in jsTestDriver.conf although a few older versions do (such as 1.3.3d), which is a problem if you want to place the test driver separate from the system under test rather than in a parent folder, or if you want to reference another framework such as Jasmine if it is placed in another directory.

\subsection{Testability, TDD, exposing code to tests, counter-intuitiveness of writing tests first}

Regardless whether or not the frameworks are effortlessly installed and configured or not, there is still the issue of testability. It is common to argue that TDD forces developers to write testable code which tends to be maintainable. This is true in some respects, but one has to bear in mind that JavaScript is commonly used with many side-effects that may not be easily tested. More importantly, it is common to place all the JavaScript code in a single file and hide the implementation using some variant of the module pattern\cite[p.~40]{GoodParts}, which means that only a small subset of the code is exposed as globally accessible functions, commonly functions that are called to initialize some global state such as event listeners. In order to test the functions, they need to be divided into parts, which will typically have to be more general in order to make sense as stand-alone modules. This conflicts with the eagerness of most developers to just get something that works without making it more complicated than necessary.

\subsection{Manual testing, psychology, refactoring}

The fundamental problem is probably that most developers are used to manually test their JavaScript in a browser. This gives an early feedback loop and although it does not come with the benefits of design, quality and automated testing that TDD does, it tends to give a feeling of not doing any extra work and getting the job done as fast as possible. Developers do not want to spend time on mocking dependencies when they are not sure that the solution they have in mind will even work. Once an implementation idea pops up, it can be tempting to just try it out rather than writing tests. If this approach is taken, it may feel like a superfluous task to add tests afterwards since that will typically require some refactoring in order to make the code testable. If the code seems to work good enough, the developer may not be willing to introduce this extra overhead. There is also a risk involved in refactoring untested code\cite[p.~17]{Refactoring}, since manually checking that the refactoring does not introduce bugs is time consuming and difficult to do well, although there is an exception when the refactoring is required in order to add tests. This is because leaving the code untested means even greater risk of bugs and the refactoring may be necessary in the future anyway, in which case it will be even harder and more error-prone.

\subsection{AngularJS, Jasmine and Karma}

The AngularJS framework uses Jasmine and Karma in the official tutorial.

\begin{quote}
``Since testing is such a critical part of software development, we make it easy to create tests in Angular so that developers are encouraged to write them''\cite{AngularTemplates}
\end{quote}

This is likely a large contributing factor for increasing the probability of Angular developers testing their JavaScript.

\subsection{Definitions}

A mock has pre-programmed expectations and built-in behaviour verification\cite[p.~453]{Tddjs}.

Because JavaScript has no notion of interfaces, it is easy to accidentally use the wrong method name or argument order when stubbing a function\cite[p.~471]{Tddjs}.

\section{Real world experiences}

\subsection{Testability issues with main.js in asteroids application}

Despite partitioning the JavaScript of the asteroids applications into separate classes, the problem of the canvas element not being available in the unit testing environment was not mitigated. The main.js file contained around 200 lines of code that could not be executed by tests without further refactoring since they were executed in a jQuery context (i.e. using \verbdef{\jquerycontext}{\$(function ()}\jquerycontext...) that included the selector \verbdef{\selector}{$("#canvas")}\selector. Efforts to load this code using ajax were of no gain, so the solution was instead to expose the contents of the context as a separate class and inject the canvas and other dependencies into that class. This required turning many local variables into attributes of the class to make them accessible from main.js such as the 2d-context.

The problem was not solved entirely through this approach though, since some parts could not be extracted. The event handling for key-presses necessarily remained in main.js and since that code could not be executed by unit tests, changes to global variables used in the event handler does not cause any unit test to fail, even though the application will crash when executed in an integration test. The problem could be solved just as before, by extracting the event handler code into a separate class that can be tested. The problem is that the event handler modifies local variables in main.js, which still can't be tested, so there has to be some test setup code to mock these when making them global, and this affects the design in a bad way by introducing even more global state.

Same goes with the main loop, which contains logic to draw grid boundaries. When refactoring main.js the main loop was left in main.js (which can not be tested) and this introduced a bug that was reproduced only when using the particular feature of displaying the grid. The feature is not important and could be removed. The bug could also be fixed by making a couple of variables globally accessible as attributes of the rendering class, but that too would introduce a code smell. A better solution was to move it into the rendering class, as it semantically belongs there.

As a consequence of being unable to extract all code from main.js into testable classes, I started to consider using selenium tests. This could actually be argued to be a sound usage of selenium because main.js is basically the most top level part of the application and as such can be more or less directly tested with decent coverage using integration tests. The Internet sources that I could find regarding how to use selenium with JavaScript depended on node.js and mocha, which I was inexperienced with using at the time. Consequently, I spent an afternoon trying to get things to work but without any real results. Posting on stack overflow asking for help could possibly have been a way forward instead of settling with manual testing.

One has to be careful when adding code to beforeEach, setUp and similiar constructs in testing frameworks. If it fails the result is unpredictable. At least when using Jasmine with JsTestDriver, not all tests fail even when the beforeEach causes failure, and subsequent test runs may produce false negatives even though the problem has been fixed. This is likely due to optimizations in the test driver and is especially apparent when the system under test is divided into multiple files and contain globally defined objects (rather than constructors). In this case, game.js contains such a globally defined object and its tests commonly fails after some other test has failed, even after passing the other test. Restarting the test driver and emptying the cache in the captured browser usually solves this problem, but is time demanding.

\subsection{JsTestDriver evaluation}

When resuming from sleep on a mac the server needs to be stopped and the browsers need to be manually re-captured to the server, or else the driver hangs when trying to run the tests. This is both annoying and time consuming. However, the problem is not present on a windows machine (and it might not be reproducable on all mac machines either). In the interview with Johannes Edelstam, he agreed that this is one example of something that deters people from testing\cite{Edelstam}.

Definitions are not cleared between test runs, meaning that some old definitions from a previous test run can remain and cause tests to pass although they should not because they are referring to objects that no longer exists or that tests can pass the first time they are run but then crash the second time although no change has been made to the code. Some of these problems indicate that the tests are bad, but it is inconvenient that the tool does not give you any indication when these problems occur, especially when there is false positives.

If there is a syntax error in a test, the JsTestDriver still reports that the tests pass. For example:

\begin{verbatim}
setting runnermode QUIET
...................................
Total 35 tests (Passed: 35; Fails: 0; Errors: 0) (23,00 ms)
  Chrome 27.0.1453.94 Windows: Run 36 tests (Passed: 35; Fails: 0;
Errors 1) (23,00 ms)
    error loading file: /test/sprites-spec/sprite-spec.js:101: Uncaught
SyntaxError: Unexpected token )
\end{verbatim}

As a developer, you might miss the ``error loading file'' message and that not all 36 tests were run, because the first line seems to say that everything went fine. Sometimes Jasmine does not run any test at all when there is a syntax error, but does not report the syntax error either. It is therefore recommended that you pay close attention to the terminal output and check that the correct number of tests were run rather than just that there was no failures. This is impractical when running the tests in a CI build because the build screen will typically display success even if no tests were run. It can be of help to keep a close look on the order in which files are loaded and also to keep the console of a browser open in order to be notified of syntax errors\cite{MikeJansen}.

Many of these problems can be said to stem from accidental integration tests or other errors in the tests. It should be noted however that proper stubbing of dependencies can be a daunting task, especially if dependency injection is not handled in a smooth way. In JavaScript, dependency injection can be argued to be harder than in for instance C or java because of the absence of class interfaces. The sinon.JS framework does simplify compared to manual stubbing (which on the other hand is exceptionally simple to do with JavaScript) but there is still issues of doing tradeoffs between dedicating many lines of code to stubbing, quite often having to repeat the same code in multiple places, or risk introducing bugs in the tests themselves. As a programmer you have to be very methodical, principled and meticulous not to miss some detail and write an accidental integration test. Such mistakes leave you with misleading failure result messages and sometimes the tests fail because of the order in which they are executed or similar, rather than because of an actual bug in the system under test.

Another source of problems is when global state is modified by constructors of different classes. For instance, when extracting code from main.js into rendering.js, part of that code was involved with initiating the grid which is shared between all the sprites in the application (through its prototype) and this meant the the grid was not defined unless the rendering class had been instantiated. This imposed a required order in which to run the tests and is an example of poor maintainability due to optimization.

Deficiencies such as these are important to note because they pose potential reasons to why JavaScript developers don't test their code. If using the tools and frameworks is perceived as cumbersome and demanding, fewer will use them and those who do will consider it worth doing so in fewer cases.

When a function is defined within a constructor it is hard to stub unless you have an object created by the constructor available. In some cases you don't because the system under test creates an instance by itself and then you are (as far as I know) out of options except for stubbing the entire constructor (this produces a lot of code in the tests) or changing the system under test to increase testability, for instance by having the instance passed as an argument (which allows for dependency injection but can be odd from a semantic point of view) or defining the functions that you need to stub on the prototype of the constructor instead of in the constructor (which allows for easy stubbing but is less reliable since another class/object can modify the function as well). Often it is possible to come up with a way that increases testability without having a negative impact on readability, performance, etc. of the system under test, but not always so. Regardless, this requires a skilled programmer and effort is spent on achieving testability rather than implementing functionality which may feel unsatisfactory.

JsTestDriver is not perfect. When refreshing and clearing the cache of a captured browser, you have to wait for a couple of seconds before running your tests or else the browser will hang and you have to restart the server. This wouldn't be such a problem if it wasn't because definitions from previous test runs remain in the browser between runs. For instance, if a method is stubbed in two different tests but only restored in the one that is run first, the tests will pass the first time they are run but then fail the second time. Realizing that this is what has happened is far from trivial so as a beginner you easily get frustrated with these small issues, since you might refresh the browser quite frequently in the process of finding out.

Having spent many hours debugging, I finally decided to do a thorough check that no test depended on another test or part of the application that is not supposed to be tested by a specific test. In short, I wanted to ensure that the tests I'd written were truly unit tests. In order to do this, I created a copy of the application repository, deleted every file in the copy except for one test and the corresponding part of the application. Then I configured a JSTD server with a browser to run only that test, and repeated the process for every test. This method does not guarantee absence of side effects or detecting tests that do not clean up after themselves, but being able to run a test multiple times without failing, in complete isolation with the part of the application that it is supposed to test, at least gives some degree of reassurance that all external dependencies have been stubbed. If any external dependency has been left unstubbed the only way for the test to pass is if the code exercising that dependency is not executed by the test, and if a test does not clean up after itself it is likely to fail the second time it runs although this too depends on how the tests are written.

\subsection{Testability and other issues with adding tests to an existing application}

Sometimes it can be hard to know whether or not to stub library functions such as \$.isFunction or if you should trust that they behave as expected and steer the control flow via their input and the global state instead. The same applies to simple functions you have written yourself that you think are free of bugs. Not stubbing external dependencies leads to fewer lines of test setup and teardown code and usually better test coverage but can also impose a danger of the unit tests becoming more brittle and similar to integration tests.

When adding tests to an existing application, it is easy to lose track of what has and what has not been tested. Having access to a functional specification of the application can be of help but it might be unavailable, incomplete or outdated. Then you have to make a specification of your own, in order to be systematic about what tests you write. This can be done top-down by looking at user stories (if there are any), talking with the product owner and the users (if any) or identify features to test through manual testing. It can also be done bottom-up by looking at the source code that is to be tested and come up with ideas regarding what it appears like all the functions should be doing. The latter is what was done before adding tests to the asteroids application because there was no documentation available and the application was so small that a bottom-up approach seemed feasible and likely to generate better coverage than doing a top-down specification. The way this was done was by writing test plans in the form of source code comments in the spec files for each class.

Each function was analyzed with respect to what was considered to be its expected behavior, such as adding something to a data structure or performing a call with a certain argument, and then a short sentence described that behavior so that it would not be forgotten when writing the actual tests later. Since tests are typically small, one might think that it could be a good idea to write the tests directly instead of taking the detour of writing a comment first, but my experience was that a comment is a lot faster to write than a complete test, makes up for fewer lines of code and avoids getting stuck with details about how to write the test.

Another useful method for knowing what tests to write was to write tests for every bug that was detected, i.e. regression testing. This should be done before fixing the bug so you can watch the test fail, which increases the chance that the test will fail if the same bug is introduced again. Additionally, some aspects of TDD can be employed even when the code lacks tests by writing tests that document any changes you make to the application. Be careful that you do not break existing functionality though, and that the tests focus on behavior rather than implementation details. The recommended approach is writing tests for the application in its existing form before starting to change it, since this will increase understanding of how it works and reduce risk of breaking existing functionality when refactoring later. These alternatives are still worth mentioning though, because sometimes code needs to be refactored in order to make it testable.

Traditionally, coverage criteria has been a central concept in software testing and is still today in many organizations (citation needed). When doing TDD however, the need for thinking in terms of coverage is reduced as every small addition of functionality is tested beforehand. There is no need to test specific implementation details because that will only make the system harder to change. If a certain function feels complex and likely to contain bugs, the recommended way in TDD is to take smaller steps, refactoring and testing new components separately rather than trying to achieve different kinds of graph and logic coverage for the complex function. When adding tests in retrospect it makes more sense to think about coverage, which may be done when the system is starting to feel complete in order to reduce risk of bugs. There are various tools available for ensuring that relevant parts of an application are exercised by tests and it is often relevant to design tests based on edge cases and abnormal use. As a tester, it tends to pays off having the attitude of trying to break stuff instead of just testing the so called happy flow. Different types of coverage criteria can help in formalizing this, as described in Introduction to Software Testing by Ammann and Offutt\cite{AmmannOffutt}.

To illustrate why achieving a certain coverage criteria should not be a goal in itself, I decided to write tests for the finite state machine (FSM) in the asteroids.Game object of the asteroids application. Achieving Clause Coverage\cite[p.~106]{AmmannOffutt} for 18 lines of production code (asteroids.Game.FSM.start) took almost 100 lines of test code, see commit 61713c of \url{https://github.com/emilwall/HTML5-Asteroids}. This is not that much, but it didn't provide much value either as no bug was found.

\subsection{Stubbing vs refactoring}

When an application is tightly coupled, stubbing becomes a daunting task. What you end up with is deciding whether you should compromise the unit tests by not stubbing everything, refactor the code to reduce the amount of calls that needs to be stubbed, or stub all dependencies. The first alternative bodes for unstable tests that might fail or cause other tests to fail for the wrong reasons. Refactoring might introduce new bugs and should probably only be done if it simplifies the design and makes the code more readable. Stubbing all dependencies might result in too much code or force you to complicate the testing configuration so that some code is run between each test. One case where this tradeoff had to be made was when writing tests for classes that depended on the Sprite class, such as the Ship class. It uses the Sprite class both for its ``exhaust'' attribute and for its prototype. Luckily, the Sprite constructor does not modify any global state, so in this case not stubbing the Sprite class before parsing the Ship class is acceptable. In the unit tests however, any calls to methods defined in Sprite are preferably stubbed, since they should be tested separately.

To detect improper stubbing, I ran each test isolated with just the file it was supposed to test. A problem with this was that trying to stub a function which is not defined produces an exception in order to prevent you from doing typos. This could be solved by saving the implementation in a local variable, defining the function to be an empty function, stub it with sinon.JS and then restore and re-set it to the original implementation, but this is inconvenient so instead I opted towards being careful not to miss any calls that should be stubbed. There is a point with interpreting the system under test before running any test code, since that allows for detection of typing mistakes and other integration issues.

\subsection{Deciding what to test}

During the interview with Johannes Edelstam, one of the things that came up was that you should focus on testing behaviour rather than appearance and implementation details. This is a good excuse for not testing that a certain class inherits from another but rather focus on that the methods of that class behaves as one would expect. Whether or not that is dependent on the inheritance patterns is mainly relevant for stubbing considerations - you may want to replace the prototype of an object in tests so that you can check that there are no unexpected dependencies.

Another thing that came up during the interview with Johannes Edelstam was that when something feels like it is hard to test, it is likely that any test you write will become rather brittle as the code changes in the future. The proposed solution (TODO check this from the recording!) was to avoid testing it unless the code can be refactored so that testing becomes easier. When writing the tests for the asteroids application, I deliberately chose to write tests even when it felt hard or felt like it provided little value, to see whether this made the application harder to test later and if people would remove the bad tests during the workshop.

\subsection{Meetup open space discussion}

During a talk at a meetup on python APIs (2013-05-22 at Tictail's office, an e-commerce startup based in Stockholm), the speaker mentioned that their application depended heavily on JavaScript. It turned out that they had done some testing efforts but without any lasting results. During the open space after the talks, testing became a discussion subject in a group consisting of one of the developers of the application, among others. The developer explained that they had been unable to unit test their JavaScript because the functionality was so tightly coupled that the only observable output that they could possibly test was the appearance of the web page, via Selenium tests. He sought reassurance that they had done the right thing when deciding not to base their testing on Selenium due to instability (tests failing for the wrong reasons) and time required to run the tests. He also sought answers to how they should have proceeded.

The participants in the discussion were in agreement that testing appearance is the wrong way to go and that tests need to be fast and reliable. The experience with testing frameworks seemed to vary, some had used Jasmine and appreciated its behaviour driven approach and at least one had used Karma but under its former name Testacular. The idea that general JavaScript frameworks such as AngularJS could help in making code testable and incorporating tests as a natural part of the development was not frowned upon. The consensus seemed to be that in general, testing JavaScript is good if done right, but also difficult.

\subsection{Ideas spawned when talking about this thesis}

During my work on this thesis, I have explained to numerous people what it is that I'm doing. Typically, I've started out with saying something like ``I'm looking at testing of JavaScript''. Depending on if the person asking knows a lot about JavaScript or not, the conversation then might proceed in different directions, but the most common follow up is that I explain further that I'm looking at why people don't do it, when and how they should do it and what the problems and benefits are. Especially I'm looking at the problems.

One not so uncommon response is that testing of JavaScript probably is so uncommon because people programming in JavaScript often have a background as web graphic designers, without that much experience of automated testing. Another common conception is that JavaScript in practise is usually not testable because it has too much to do with the front-end parts of an application, so tests are inevitably slow, unmaintainable and/or unreliable because of the environment they have to run in.

\subsection{Interview summary}

The interview with Johannes Edelstam raised many interesting points, which are summarized in this section.

It seems that in the last couple of years, the number of people testing their JavaScript has increased significantly\cite{Edelstam}. This has been observed through asking people that do it to raise their hands during tech talks, two years ago only a few raised their hands when asked such a question whereas now almost every single one does it.

According to Edelstam, a likely reason for this change is that the tools have become better and that there are more examples of how to do it. This has caused the opinion that JavaScript is too user interface centered to recede, as people have realized how it can be done. Few people were ever against TDD or testing in general, much thanks to positive experiences from testing in Ruby on Rails projects, which actually act as great examples of that testing wide ranges of interfaces is possible and that many feel that it is necessary. Perhaps the most common reason for not testing is that the code has not been written in a testable fashion. \cite{Edelstam}

A common experience when writing tests is that you put a lot of effort into the tests and do not write that much production code in comparison, but that can be a good thing! Because then you spend more time thinking about the problem and possible abstractions, which tends to lead to elegant solutions. If you write the tests before the code, you will run into the same problems as you would have done if you wrote the code first, the difference is that you get to think about the design rather than staring at incomplete code when solving the problem. \cite{Edelstam}

The feeling of being limited and not productive when writing tests can stem from a badly chosen level of ambition or that the focus of the tests is wrong, which in turn can be based on poor understanding of what tests are good for. Coding without tests can be much like multitasking, you get an illusion of being more productive than you actually are. One of the positive effects of TDD is that it can prevent you from losing track of direction, and helps you in making clear delimitations, since trying to be smart by allowing a function to do more than one thing means more tests. Testing will not automatically provide you with good ideas regarding where you are heading, but once you have gotten such an idea, testing tends to be easier and help you discover new aspects and scenarios which might would have been left unnoticed without tests. \cite{Edelstam}

When deciding what to test, it pays off to focus on parts that are central to how the application is perceived, for instance pure logic and calculations might be more important than pictures and graphs. An error that propagates through the entire application is more serious than if a single picture is not displayed properly. If a test turns out to be difficult to write or frequently needs to be replaced by another test, it is usually worth considering not testing that part at all. \cite{Edelstam}

In June this year, Kent Beck wrote the following tweet\footnote{A tweet is a message sent to many using the social media \url{www.twitter.com}}:

\begin{quote}
``that was tough--it almost never takes me 6 hours to write one test. complicated domain required extensive research.''
\end{quote}

One of the responses was that many would have given up on writing that test. Beck replied that if you don't know how to write the test, you don't know how to write the code either\cite{TwitterKentBeck}. What many probably fail to realize about why testing can be time consuming and hard, is that when writing tests you encounter problems that you would have to solve anyway. The difference is that you solve the problems by formulating tests rather than staring at production code for the same amount of time. \cite{Edelstam}

Tools are an important part of facilitating testing, so that people are not so deterred by the initial effort required to get started. Yeoman is one example of a framework that can help you in quickly getting started with a project that is structured so that testing becomes easier. For already existing projects, the increased maturity of tools such as PhantomJS and Mocha is also truly helpful. \cite{Edelstam}

Error reports are useful feedback that tests provide. The quality of these reports vary depending on which testing frameworks you are using and how you write your tests. When using PhantomJS to run tests, some test failures require you to run the tests in a browser in order to get good error reports. \cite{Edelstam}

An important difference between using a headless browser such as PhantomJS to run your tests compared to JsTestDriver, or other drivers that allow you to test in several browsers, is that a headless browser provides no information about how your code performs on different JavaScript implementations. Reasons why you might still decide to do so include speed, easier integration with build tools such as Jenkins, and that it yields the same results as long as the tests focus on logic rather than compatibility. \cite{Edelstam}

% TODO: section: Ways of testing, selenium vs unit test in browser. headless vs real browser.

One could argue that JavaScript is better suited for testing than most other programming languages because of the built in features than often make stubbing frameworks redundant. The object literals can be used to define fake objects and it is easy to manually replace a function with another and then restore it. An advantage with using manually written fakes is that it tends to make the code easier to understand since knowledge about specific frameworks or DSLs (Domain Specific Language) is not required. \cite{Edelstam}

The problems that some people experience with testing frontend interfaces sometimes have to do with poor modularity. For instance, the presentation layer should not be responsible for calling large APIs. Tools such as RequireJS can be used to handle dependencies but if each part of the application has too many or large dependencies, mocking becomes daunting. Typically, these kinds of problems can be solved by introducing new layers of logic and services that separate responsibilities and allows for much cleaner tests. \cite{Edelstam}

A common case of user interface testing is form validation. Being test driven does not necessarily mean that you should test that the form exists, has a working submit button and other boilerplate things, unless the form is written in a way that is unique or new to you in some way. A typical approach would rather be to write the code for the form and then add a test that searches for a non-existing validation. The difficult part here is to strike a balance and be alert to when the code is getting so complicated that it is time to start testing, and to avoid writing tests when they are in the way and provide little value. \cite{Edelstam}

Being too religious about testing principles leads to conflicts like ``writing tests take too much time from the real job''. If the tests do not provide enough value for them to be worth the effort then they should be written differently or not at all. There is no value in writing tests just for the sake of it. Thinking about architecture and the end product can be a good thing even when there are no tests, because awareness of the bigger picture is also important. There is the same risk with tests as with other pieces of code, sometimes you are especially proud or fond of a certain test and unwilling to throw it away, in order to avoid that situation it is often better to think ahead and try things out than to immediately spend time writing tests. \cite{Edelstam}

Writing implementation specific tests is a common phenomena that can stem from poor experience of writing tests, extreme testing ambitions or, perhaps most commonly, poor understanding of the system under test. These kind of tests should be avoided since they tend to be hard to understand and usually have to be changed whenever an improvement of the implementation is considered. A large number of tests is not necessarily a good thing either, it is harder to overview and maintain a large collection of tests. Unless the system is inevitably so complicated that extensive testing is justified, it rarely pays off to strive for 100 \% coverage, since it takes too much time and the scenarios that might cause problems are at risk of being overlooked anyway. \cite{Edelstam}

Tests can serve to prevent people from breaking code and as examples that help new people understand how an application works and how to continue development \cite{Edelstam}. Tests also help to give a clear image of how components fit together and can be a way to concretize a feature or bug.

\subsubsection{Testing private APIs}

Testing private APIs differs from testing calls to an external API in that the latter are often well documented, versioned and rarely changes. When using an external API, the main concerns are making sure that the correct version is used and that the API is called in a correct way with respect to that version. A private API on the other hand may change frequently which means that the fake objects representing requests and responses of the API in other tests need to change as well.

Introducing versioning for private APIs is not always feasible, for at least two reasons. There can be difficulties in keeping track of the different versions and there can be a risk of hampering development since the parts that use the API are dependent on the new version of the API to be released before they can be updated. However, there exists testing techniques that can be employed regardless if versioning is in place or not. One such technique is to write tests for what characterizes an object that the API serves as an interface for, to be able to determine if an object is a valid response or request. These tests can then be used on both real objects and on the fake objects that are used in other tests, which means that when the API changes the tests can be updated accordingly and then the tests involving the fake will fail. Changing the fakes so that the tests passes will hopefully result in that any incompatibility is discovered since the fakes are used in other parts of the testing suite as well. \cite{Edelstam}

\printbibliography[heading=bibnumbered]

\section{Appendix}

\subsection{Transcript of Interview with Johannes Edelstam}

\emph{Vad r dina erfarenheter av hur folk testar sitt JavaScript?}

Fr 1,5-2 r sen, hll jag i en trff om testning av JavaScript. Jag hade handupprckning och frgade Hur mnga testar sitt JavaScript?. D var det bara tre personer som hade gjort det verhuvudtaget. Nu, nstan tv r senare, r i princip alla hnder i luften. Trenden har gtt frn Vad konstig du r som testar ditt JavaScript till Vad kr du fr tools p bara ett och ett halvt r.

\emph{Vad tror du har lett till det?}

Verktyg, dels att de har blivit bttre och att det finns fler exempel p hur man gr. Folk var inte emot testning eller test-driven utveckling, mnga Ruby-utvecklare hade redan positiva erfarenheter av att testa, men hade instllningen att JavaScript var fr inriktat p grnssnitt fr att det ska g att testa det.

\emph{Det tycker jag att man fortfarande kan se lite grann.}

Samtidigt r det konstigt att sga s, fr i ett Ruby-projekt testas saker och ting rigorst, trots att det r en massa grnssnitt som du testar igenom. Det handlar bara om att det r dlig tooling, inte att det inte behvs gras.

En annan aspekt kan vara att folk helt enkelt skriver kass kod. Om man i ett lge inte vet hur man ska testa en viss sak s kan det vara s att det inte gr fr att koden inte har skrivits p ett stt som gr den testbar.

\emph{Jag funderar p om att anvnda ramverk som strukturerar upp koden r en lsning fr att faktiskt kunna testa kod bttre.}

Vad tnker du p fr ramverk?

\emph{Det jag hittills hunnit skaffa mig erfarenhet av r AngularJS, som har vyer och controllers. Controllers r enkla att testa.}

Precis.

\emph{Sen det hr spelet som jag tnkte kra en workshop om framver, det kanske jag inte har berttat ngot om. Jag tnkte kra med ett arkadspel, Asteroids, och TDD:a lite p det.}

Schysst.

\emph{Det r inte uppbyggt kring ngot ramverk, men r uppdelat i klasser och knns i allmnhet som rtt s schysst kod. D gr det att testa. Det fanns inga tester, s det har jag lagt till nu i efterhand (vilket har varit lrorikt). Jag tror att om man inte r spass duktig som han som skrev det var, och faktiskt r s disciplinerad att man ser till att dela upp s att det bildas klasser med metoder som gr att testa, s blir det kaos.}

Verkligen.

\emph{Det dr med Ruby vs JavaScript har jag sett innan ocks, jag inleder min rapport med det just nu, ett liknande citat som det du just sa, bara att det var frn nr det fortfarande bara var tre hnder.}

Det r vanligt och gller verallt, folk gillar att hitta urskter till varfr man inte ska testa grejer. Det r en liknande paradox som den att man tror att man blir s effektiv nr man multitaskar, man luras att tro att man begrnsas av testerna. Det som folk ofta menar nr de sger att de begrnsas av testerna r att de i sjlva verket inte riktigt vet vart de ska. Om man inte vet vad det r man ska bygga och hur allting ska fungera s tar det vldigt lng tid om man ska test-driva ngon form av lekstuga. Det blir rtt stkigt, s dr handlar det om att hitta bra egna principer fr hur man tar sig fram till den punkt d man vet vad ngot ska bli. Nr man vl har en klar bild av vart man vill s r det ofta ganska ltt att brja skriva tester och det vcker bra tankar som man inte har sttt p nr man tagit sig fram till sin mlbild.

Det som ofta blir nr man skriver tester r att man lgger mycket av sin tid och sitt fokus i att skriva testerna p ett bra stt och knslan blir att man inte skriver lika mycket av produktionskoden. Vilket r en bra sak! Fr d gnar man en massa tid t att fundera p problemet och hur man ska boxa in det. Det leder till eleganta och sm lsningar, fr att man lyckats skapa sig en uppfattning om vad problemet r.

Framfrallt blir man bttre p att gra begrnsningar, om man kodar utan tester s r det ltt att man kommer p att en viss funktion skulle kunna gra flera saker, medan om man skriver tester fr koden s r det enklare att inse att en extra parameter kan innebra att det behvs dubbelt s mnga tester. Just i JavaScript r det ett vanligt misstag att frng single purpose-principen och det kan man allts undvika med hjlp av tester.

\emph{Ja, i JavaScript r det ju enkelt att skriva funktioner som tar olika antal parametrar och bara kr p oavsett hur de anropas.}

Jag skulle sga att jag testar betydligt mer av just logik-kod n till exempel grafer. Det r mest fr att de ndras snabbt och risken fr fel r lgre. Det r vrre att ha ett konsekvent logik-fel n om en stapel blir lite fr kort.

\emph{Du tnker p Tink?}

Ja, precis. Det r samma mnster som nr jag testdriver Ruby-kod. Man driver beteende, inte utseende. Sen tror jag ocks att det har att gra med att det r dliga tools, det r omstndigt att skriva hllbara och vrdefulla tester fr att en svg har rtt parametrar. I situationer dr ngot kan vara rtt nd, fast det inte r precis som man skrev, s uppstr brckliga tester om man inte har tagit hnsyn till detta nr man skrivit sina tester. Dliga tester knnetecknas av att man behver ta bort dem fr att kunna komma vidare i utvecklingen. Det r en svr grnsdragning var man ska lgga sin energi.

\emph{Jag lste ett inlgg p twitter alldeles nyss av Kent Beck, om att han hade spenderat 6 timmar p att skriva ett test. Han hade researchat och konstaterat att det var ett komplicerat domn och ngon ppekade att detta var anledningen till att folk inte skriver tester, att andra hade gett upp hr. Kent Beck kontrade med att om han inte vet hur han ska skriva testet s vet han verkligen inte hur han ska skriva koden.}

Exakt! Det dr r jtteintressant, jag tror att folk hnger upp sig fr mycket p att det r att skriva testerna som r svrt. Om man stter sig och skriver testerna frst s r det dr man springer p problemet. Ngon annan hade skert lagt samma sex timmar fast p att stirra p produktionskod.

Sen knde jag att det har lite med vana att gra ocks. Nu nr jag skrivit tester till det hr spelet p senare tid, s gr det mycket fortare att se vad som gr att testa och hur testkoden kan skrivas. I brjan blev jag frustrerad ver de nybrjarmisstag jag gjorde.

Det r en viss startstrcka s att det tar lngre tid att komma igng, vilket avskrcker folk. Det dr har blivit mycket bttre genom verktyg som Yeoman och Brunch, dr man fr projekt med tester och allting uppsatta, det r bara att brja skriva ungefr som i Ruby on rails. Sdant gr att folk blir mer vnligt instllda till tester.

I brjan nr jag kollade p det hr s var det vldigt experimentellt att verhuvudtaget kra tester i terminalen. Innan PhantomJS var bra s fanns det headless drivers som var svra att anvnda.

\emph{Hur bra r PhantomJS nu?}

Nu r det bra, jag kr testerna i princip jmt genom PhantomJS. Det kunde fortfarande vara bttre, men fr det mesta s r det nog testramverken som inte anvnder det p rtt stt. Vissa test failures mste man fortfarande dra upp i browsern fr att f bra felrapportering. Vi kr vra tester i PhantomJS i byggen p Jenkins, s det r en del av byggfldet.

\emph{Det jag har gjort nu r att jag har anvnt JsTestDriver, det knns som att det kan vara knepigt att f in det i Jenkins.}

Det r det skert, men dr handlar det om att man mste skilja p tester som testar ren logik dr vrdet av att testa i en massa olika webblsare kanske inte r sdr gigantiskt stort.

\emph{Nej, mina tester skulle jag kunna kra headless.}

Exakt, och d kan man lika grna kra dem i ngot abstrakt som till exempel phantom, fr du fr samma resultat och det r mycket smidigare. Jag har i och fr sig inte provat att stta upp JsTestDriver och har nog aldrig krt det faktiskt och har hllt mig till andra verktyg.

\emph{Det r egentligen bara att man har en jar-fil som man anvnder som lokal server och s skickar man requests dit. Det r smidigt att anvnda men oklart hur det skulle funka med Jenkins, eftersom man behver hooka upp webblsare mot servern fr att ha ngonstans att kra testerna. Att f det att ske automatiskt r kanske inte trivialt. Dessutom s har det varit lite buggigt, att om ngot test handlar i en ondlig loop s har jag varit tvungen att stnga ner den fliken i webblsaren, starta om servern och teransluta. Nr jag satt med Mac innan s var jag tvungen att starta om servern varje gng datorn gtt i vntelge, typiskt sdant som man som anvndare blir frustrerad av.}

Snt kan vara vldigt irriterande och det r sdana saker som gr att folk inte vill hlla p med tester.

\emph{Du hade anvnt Mocha rtt mycket, det tnkte jag titta p sen.}

Mm, vad kr du nu?

\emph{Nu kr jag JsTestDriver och Jasmine.}

Det r vldigt likt, Jasmine och Mocha.

\emph{S du kr Mocha istllet fr Jasmine?}

Ja.

\emph{r Mocha en test driver? Fr Jasmine kan vl inte kra testerna i en webblsare, utan r i frsta hand ett assertion framework?}

Det var s lnge sen jag krde det, men ja man kanske behver ha en driver till det fr att kunna kra i webblsaren.

\emph{Jag har uppfattat det som att Mocha r lite mer kompetent som driver och liknande.}

Ja, det r det. Det r enkelt att dra upp tester i webblsaren om man vill ha det.

Jag gillar nstan bttre att skriva tester i JavaScript n i Ruby, det finns s mycket praktiska sprk-features.

\emph{Att manuellt kunna definiera om en funktion.}

Precis, och hur ltt det r att gra nya fake-objekt, det r s enkelt. Ofta blir mocknings- och stubbningsramverk ganska verfldiga, frutom till att gra vissa call-assertions som man anvnder det till, men i vrigt s frsker jag att alltid hlla mig till fakes som r skrivna fr hand fr att det blir lttare fr ngon annan som stter sig in i det.

Nr nsta person tittar p koden s r det en frdel om den personen inte behver lra sig ett helt ramverk eller stta sig in i hur DSL:er r uppbyggda bara fr att frst testerna. Om det bara r vanlig JS-kod s blir det ltt fr folk att frst vad det r som hnder, s p det sttet r JavaScript vldigt vl lmpat fr att skriva tester till.

Sen kan det vara s att hela Node-rrelsen ocks har bidragit till att det testas mer.

\emph{Det har vl ocks ndrat vad JavaScript anvnds till, rtt mycket?}

Ja, det har det garanterat.

\emph{Argumentet det r grnssnitt s det r svrt att testa hller inte riktigt. Jag fokuserar p klientsidan nu, fr att jag var tvungen att avgrnsa p ngot stt och fr att det knns som att problemen ligger p grnssnitt snarare n Node och liknande.}

Om vi tar ett login-formulr som exempel, med en vy-klass som du kan anropa render p. Alla dependencies, inklusive templates, som den anvnder, laddas via RequireJS. S i mitt test s anvnder jag RequireJS fr att f in den filen och d r den redo att kra och det gr att anropa render. Hr gller det att ha sina dependencies rtt, fr om den vet om en massa saker utanfr s uppstr situationer dr man behver mocka vldigt mycket.

Det r ytterligare en frdel med tester, att det blir tydligt vad som krvs fr att kunna anvnda ett visst objekt och man blir uppmrksam p dependencies som inte ska vara dr. Bara genom att anropa render och gra en submit p formulret s hanteras det i vyn och man kan testa att rtt tjnster anropas, m.m. Igen s handlar det om att man mste hitta bra modularitet i hur man lgger upp det, s att man inte gr anrop direkt till ett API frn en vy, utan ha ett servicelager emellan s att man kan swappa ut testerna och kolla att den gr mot servicelagret. Det r snt som folk fastnar p, att man har fr dlig separation.

\emph{Vid sjlva utvecklingen av det hr, vad skriver du tester fr frst d? Skriver du tester fr vyerna innan du har de hr tjnsterna igng?}

Det beror p, det typiska man vill testa hr r en validering. I det fallet skulle jag stta upp formulret frst och sen fixa ett failande test som letar efter en validering som inte finns. Frst drefter skriva sjlva valideringen. Man fr ta det till en bra niv, det knns inte jttevrt att testdriva varje steg av boilerplate-grejer nr man vet exakt vad det ska bli och det nstan r copypaste-varning p det man gr. D ger det mer att testdriva nr man brjar komma till nsta niv. Det knner man sjlv, nr man mste brja tnka efter.

\emph{Det gller att hra de varningssignalerna.}

Ja, det hr tror jag ocks r det svra med testning, att det handlar om avvgningar. Det r som allt man gr med kod, att man mste ha med sunt frnuft nr man gr det. Folk gillar att stta upp principer och det tror jag att andra blir provocerade av. Principer behver anvndas i sitt sammanhang och man fr inte bli fr religis kring dem. Man behver knna nr det ger ngot och nr det r i vgen.

\emph{Mm, det jag hoppas f som slutsats i mitt examensarbete r ngot i stil med om du r i den hr situationen, gr s hr. Om du gr en sn hr app, anvnd ett ramverk av den hr typen.}

Ja, men d tror jag tyvrr att du kommer att landa i att r du i den hr situationen, anvnd ditt sunda frnuft.

\emph{*bda skrattar*}

Fr det dr tycker jag att man ser rtt tydligt, som nybrjare s behver man kunna reglerna fr att bryta mot dem. De som r mer seniora kan reglerna och r inte s rdda att bryta mot dem nr de r i vgen. Man mste vara vldigt pragmatisk med sina principer. Det r om man inte r det som det uppstr konflikter av typen att skriva tester tar s mycket tid frn det riktiga jobbet. Om det inte ger dig ngot vrde att skriva tester, gr inte det d! Det r ingen id att gra det om du inte tror p det. Om du har ngot bttre stt, go ahead! Om 20 r s r det kanske inte TDD som r grejen lngre fr att det kommit fram mycket smartare stt och det kanske r ditt stt.

Man mste se testning som ett verktyg man har, ngot man kan ta fram och stdja sig p i vissa situationer. Man kan ocks hamna i att man blir s inne i BDD och TDD att man slutar tnka. Att tnka p arkitektur blir ngonting fult, man ska skriva tester frst, det r det enda man fr gra frst. Att st vid en whiteboard och rita blir pltsligt att g hndelserna i frvg och det tror jag r farligt.

Man ska inte glmma att precis som ens kod ltt blir ens baby s kan ens tester ocks bli det. Man kan skriva tester som man r riktigt njd med och d kommer det att ta emot att kasta den koden. Det ska man akta sig fr, att bli fr kr i sin kod. D mste man ibland tnka till lite frst, innan man bara stter sig och hamrar igng. Dr mste man hitta sin avvgning i vad man tror p.

\emph{Jag funderar nu p vilken niv man vljer att hlla testerna p. De flesta av testerna jag skrev till asteroids-applikationen terspeglade hur jag frvntade mig att programmet skulle bete sig. Sedan var det ngon kod som var rtt dligt modulariserad och d hamnade testerna vldigt mycket p detaljniv och det blev vldigt mnga tester som var svra att verblicka. Testerna kan ju bli som en kravspecifikation och det r svrt att lsa dem som en sdan nr det blir fr mycket. Jag funderar p hur man egentligen ska tnka, ska man hlla en jmn niv? Om man brjar inse att ok, nu skriver jag vldigt mycket tester p detaljniv, jag kanske borde slnga de hr testerna och skriva om koden istllet?}

Ja, egentligen s tror jag att det dr r sdant som man verkligen mste knna efter vid varje situation. Om man till exempel har en jttekomplicerad och ointuitiv prisberkning, fr all del, skriv hur mycket tester du vill, men jag ser inget egenvrde i att ha en 100-procentig test coverage, fr det slinker nd igenom saker. Det finns alltid scenarios som du inte har tnkt p. Det r frmodligen det fallet du inte har skrivit ett test fr som skapar problem, och det r fr att du inte kom p det nr du skrev testerna. Det finns ingen strre mening med att frska trycka in alla fall, utan det viktiga r att man skapar en knsla av att tcka in det ganska bra, att man har rimliga fall och framfrallt tnka p den som kommer efter.

Om du ppnar en fil med 700 rader testkod s kommer du inte att engagera dig p samma stt fr det r fr svrt att frst sig p all den koden. Dr mste man verkligen anvnda sunt frnuft och det var ocks ngon tweet jag lste att om du ber en utvecklare review:a 10 rader kod s kommer du att f hur mycket feedback som helst, om du ber en utvecklare review:a 500 rader kod s kommer han eller hon att sga att det ser bra ut. S r det ju, det r fr mycket att stta sig in i och bland annat drfr s ska man inte vara rdd fr att ta bort tester. Kasta gamla tester som inte behvs lngre.

De bsta utvecklarna som jag har jobbat med har haft ett netto att det frsvinner kod med varje commit, s att det kommer till grejer men samtidigt s frsvinner kod. Det r imponerande, och har att gra med att de r bra p att se vad som inte behvs och hur man kan tnka om, ibland genom att ndra p vissa grundantaganden fr att f koden att bli renare. Med det vill jag inte sga att man ska g ver till ngon sorts kodgolfande, men det r nd intressant att det kan bli resultatet.

\emph{Vi kom in lite p att lgga till tester till kod som redan finns, vilket jag upplever r rtt s jobbigt och frstr att du tycker r lite dumt. Men r det inte ocks risk fr dubbelarbete om man tnker att man bara skriver tester fr ny kod och erstter gammal kod som man inser inte funkar s bra?}

Det beror p vad den gamla koden r i fr skick.

\emph{Det kan vara ltt att tro att den r i smre skick n den egentligen r. Om man tar ver kod som ngon annan har skrivit.}

Javisst, om jag skulle erstta ett banksystem, d r det klart att jag skulle brja frska skriva tester fr precis den lilla biten man ska in och hrja i. Men med ny kod s tnker jag ocks som s att om man ska lgga till ngonting nytt eller bara r inne och roddar, d kan man se till att lgga till tester fr just det man gr. D gr man det som en del i det nya man skriver. Det r svrt, fr det r inte alltid det gr. En del gammal kod r s ruttet skriven att testerna nd blir s komplicerade att man mste mocka precis allting fr att ens komma till objektet och logiken dr bygger p s krngliga kedjor av anrop att testerna blir brckliga och svra att frst oavsett. Frgan r om det ger s mycket d.  andra sidan, i fallet med banksystemet, s mste det bli rtt. D mste man hitta ett stt att verifiera att systemet fortfarande beter sig rtt. Jag har nog aldrig varit i ett sdant fall att jag suttit med ngot s kritiskt som ett banksystem eller en cancerlaser eller liknande dr jag behvt erstta gammal kod, men det finns bra bcker p det dr, som tar upp de situationerna.

De gnger det inte gr att skriva meningsfulla tester s tror jag att det beror p att koden inte r skriven fr att vara testbar. Oftast nr folk pratar om legacy JavaScript s r det kod som nd inte r banksystems-kritisk. D skulle jag sga att en bttre approach r att testa allt nytt man skriver n att frska tcka in allt gammalt.

\emph{Min tanke nu var att i min workshop/kompetensdragning s vill jag ge mjlighet att se om man har rkat ha snder ngonting gammalt och se den effekten av testerna. Jag tnkte stlla ngra frgor eftert, hjlpte testerna er ngonting?}

Det r nog bra, fr det r ju ocks ett jttevrde med tester, nr man slpper in nytt folk i ett projekt. Det r alltid s att folk tenderar att ha snder grejer nr de r inne och hrjar i dem fr frsta gngen, vilket inte r s konstigt.

\emph{Och framfrallt r rdda att ha snder saker.}

Ja, precis. Finns det d en bra testsvit s r det bara att kra. Jag tror att det r ett bra stt att komma in i nya projekt ocks, genom att det finns en bra testsvit som man kan brja bygga vidare p s blir man tryggare i det man gr och kan imitera hur de tidigare testerna har skrivits. D kan man lita p det man skriver, att det blir rtt.

\emph{Vinsten med att lgga till tester i efterhand s som jag har gjort r att jag verkligen ftt lra mig, det knns nstan som att det r jag som har skrivit koden jag testat, trots att jag bara har varit och fingrat p ngra f rader i den.}

Verkligen, man fr en helt annan uppfattning fr den. Men det r en utmaning att skriva bra kod som blir testbar. Sen det hr problemet som du ocks var inne p, att det kan finnas integrationstestnings-problematiker, det kanske jag skulle vilja sga r det svraste. Fallen d man har egna API:er. Hur man ska testa det rakt igenom.

\emph{Du skrev i ditt mail att du tyckte att det var knepigt att testa privata API:er fr att de ndras s mycket.}

Sg att jag integrerar mot Twitter eller ngonting, deras API:er. Det r ltt att testa, genom att kolla att de anropas p rtt stt. Det r vldokumenterade, stora, bra API:er. Det som r problemet r att hlla hastighet nr man ndrar p sina egna API:er. Ett bra stt att gra det internt r att du har ett test fr ngon typ av domn-modell som definierar vad som gller fr en viss sak, till exempel hur ett cykelhjul ska fungera. D har man en uppsttning tester som testar att ett objekt r ett giltigt cykelhjul, och s kan man kra samma tester p sin fake av ett cykelhjul fr att verifiera att den ocks r ett giltigt sdant. Denna fake kan sedan anvndas i andra test, som gr saker med cykelhjul. Om API:et fr cykelhjulet ndras s kommer testerna fr fakeobjektet ocks att faila, eftersom samma tester anvnds p det riktiga objektet som p fakeobjektet. D uppdateras den tills den uppfyller testerna fr att vara ett giltigt cykelhjul och d kommer de andra testerna som involverar fakeobjektet att brja faila.

Egentligen skulle man vilja gra ungefr samma sak med sina egna API:er, genom att med tester definiera vad som r ett giltigt respons. D kan man ha samma tester till att kolla att API-endpointen ger ett giltigt respons och att ens fakerespons r ett giltigt respons. Problemet man ofta har r att man separerar det dr, istllet fr att ha en delad testsvit. Det blir oerhrt komplicerat, framfrallt om man skriver i olika sprk. Det r ett problem som jag vet att mnga har och som jag inte har sett ngon riktigt bra lsning p.

\emph{Och det r lite mitt emellan Selenium och enhetstester d?}

Ja, precis.

\emph{Hur stort r behovet av att ha de hr testerna?}

Tyvrr s r det stort. Dels r det ngot som ndras snabbt och s r det ngonting som pverkas mycket. Det r ju egentligen ingen skillnad p de testerna och tester mot andra API:er som du har i din kod, bara att de ligger i samma kodbas. Det r ju precis lika viktiga API:er.

P samma stt, nr du gr ndringar i en endpoint som du anvnder p ngot specifikt stlle s kan du missa att den ven anvnds p tv andra stllen. Testerna kommer inte att uppmrksamma dig p detta fr dr r anropen fakeade till att hrma endpointens tidigare beteende. S behovet r ungefr samma och uppstr nr ett team hanterar all kod. Nr ett API ligger utanfr ens kontroll s har man tillgng till dokumentation och endpoints ndras inte utan vidare, s d kan man anvnda sig av fixtures fr hur ett response ser ut och kan dessutom ofta anvnda versionerade API:er. Det r knappast troligt att ngon p twitter fr fr sig att utan vidare ndra s att till exempel users fr heta followers istllet, utan att det blir en ny version, d skulle ju allt g snder.

Ur samarbetssynpunkt, nr det gjorts en lokal verrenskommelse som inte alla ftt ta del av s kan det vara knepigt fr andra att veta vad som har beslutats om det inte finns tester som specificerar detta. Alternativet att ha ett kravdokument r inte s lockande.

\emph{Det r vl mycket det som mnga ser som vitsen med tester nu, att de blir som ett kravdokument fast ett bra sdant, som man inte behver lsa utan man kr det istllet.}

Jo men verkligen, s r det ju.

\emph{Vad skulle du ge fr tips till ngon som r ovan vid att testa? Om vi sger att du skulle ha trffat mig fr ett halvr sen, innan jag skrivit mitt frsta JavaScript-test?}

Testa inte gammal kod, haha. Idag skulle jag sga kr Yeoman, stt upp ett projekt, prova lite. Det finns tyvrr fortfarande rtt s lite skrivet om det tror jag, inga riktigt bra resurser om JavaScript-testning, men jag skulle nog rekommendera att lsa clean code-bckerna och frst vad det r du ska ha testning till. Utan den grundlggande frstelsen s r det svrt att se vrdet i det och man hamnar ltt i tankestt som men vad, trots att jag har skrivit det hr testet s kan det ju nd bli buggar. Utan att frst konceptet testning och varfr man gr det s har man svrt att vga olika verktyg mot varandra och motivera de val man gr.

\emph{Sen pratade vi ocks om att involvera alla i testningen. Det kan kanske vara en hjlp fr en enskild programmerare att istllet fr att behva kmpa fr att f testa sin kod  och hetsas till ett hgre tempo ha testning som en del av det man frvntas gra.}

Ja, absolut. Dr handlar det igen om att vara verens om att det r viktigt och att det r ett stt man vill jobba p, annars tror jag att det r svrt.

\emph{Vilka ser du som viktiga att involvera d? Teamet gissar jag r fundamentalt, men vill man ven f ut det till produktgare, till chef, till kund, till anvndare? Var vill man lgga detaljnivn?}

Det dr beror s mycket p vad det r fr kund och s vidare. Men framfrallt s kommer det i arbetet att speca upp stories och liknande, fr ven om man kan komma bort frn kravspecen s tror jag inte att man kommer bort frn kravarbetet. Frst och frmst, hur funkar prisalgoritmen, hur r prissttningen, vart kommer grejerna ifrn? Dr har man inget annat val n att jobba med produktgare och kund i att ta fram vad som ska hnda, s det r snarare att vara involverade i story-arbetet tillsammans. Dr tar man fram input till testerna s att man r verens om den. Sen tror jag inte s mycket p att man ska sitta och g igenom testerna tillsammans med kunden fr det brukar inte ge s mycket och blir ett ondigt steg.

\emph{Cucumber och liknande?}

Ja, precis. Det finns ju bra exempel p det, men man ska veta vad man hller p med om man gr det.

\emph{Vi hade en tanke i vrt tidigare projekt om att lta anvndare skriva selenium-tester genom att ha ett plugin i firefox som genererar tester, s varje gng ngon hittar ngot som inte funkar s skapas ett test fr det.}

Det r ju ascoolt.

\emph{Det blev aldrig s.}

Det vore tufft om man kunde gra det, att en anvndare fr repetera vad man gjorde. Det kan potentiellt bli hur hftigt som helst.

\emph{Hur ser du p selenium-tester i allmnhet, hur mycket tycker du att man ska anvnda det och till vad?}

Det dr r svrt, jag har krt det ganska mycket frut men det r mest fr att jag inte har kunnat f ihop en runtime annars. I en gammal webb dr man var tvungen att requesta sida fr sida s r det ditt enda stt att testa flden. Nu nr jag jobbar med en SPA (single page application) s kan man testa flden nd, d r man inte lika beroende av selenium. Jag tror inte heller p att testa flden utver att speca ner den mest grundlggande funktionaliteten.

\emph{*Lunch*}

\emph{Jag tycker att det var kul att du ser JavaScript som vilket annat sprk som helst, fr det r det verkligen inte alla som gr.}

Nej, det r lite stende p mitt jobb ocks, nr man hittar diverse bra grejer och reaktionen blir Ah, det r nstan som att programmera p riktigt och man fr flika in att de borde vara tysta.

\emph{*skratt*}

Det har att gra med vad man gr i sprket, om man anvnder ett sprk till riktiga saker s blir det ju till ett riktigt sprk.

\emph{Sen s funderar jag p alla de hr ramverken, vad det r som du brukar tnka nr du vljer vilka du ska anvnda, tycker du att det r svrt att veta vad de kan och s?}

Jag gr ofta fram och tillbaka dr, det viktigaste r att man inte stter sig i situationer dr man mste jobba mot ramverket. Det leder ofta till dligt resultat fr att det blir en massa kod som ingen frstr som motverkar en massa annan kod som ingen frstr (obegriplig kod). Det dr r ett problem som man nstan alltid hamnar i med de hr magic bullet-ramverken, som Ruby on Rails till exempel. Man inbillar sig att man har ett ramverks som gr allt t en, s att man kan gra en blogg p en kvart eller liknande. S kan det ocks vara i sm projekt, och d r det bra. Nr man dremot anvnder det i ett strre projekt s uppstr ltt en knsla av att ngot inte r riktigt som det ska. Man lgger oproportionerligt mycket tid p att anvnda ramverket till saker det inte r tnkt fr frn brjan. Frgor som hur gr man det hr i ramverket? uppstr och nr man kommit till det stadiet s r man verkligen lst i ramverket. Det blir att man frsker anpassa sig till hur ramverket r tnkt att anvndas snarare n att man tar fram sin lsning utefter den vision man har.

I fallet med rails s tror jag att en stor del av problemet r att man har felriktade dependency-pilar, man har bakat ihop persistence med domnobjekten till en kombination som r svr att reda ut.

Det viktigaste nr man vljer ramverk r att hitta ett ramverk dr man knner att man har frihet att strukturera koden som man behver. Det r samtidigt ngot som man behver knna sig fram med.

\emph{Jag tnker p det du sa om integrationstestning, att man ofta har separerat det, det skulle kanske kunna vara en ramverksfrga ocks? Om man har ett ramverk dr man fr uppfattningen av att man behver strukturera koden p ett visst stt s kan det hindra en frn att skriva integrationstester fr saker som tvingats isr av ramverket?}

Det r ett stort problem och ngot man inte vill hamna i, att man inte kan testa grejer fr att ramverket sger s. Det r verkligen grunden i att vlja ramverk att man mste kunna undvika det.

\emph{Du sa att du grna har ganska sm ramverk.}

Ja, och dr kan man nmna backbone som ett exempel. Jag gillar att det hller sig ur vgen (unobtrusive). Den ger frslag till hur man ska gra vissa grejer som har med infrastruktur att gra och sen s fr jag sjlv bestmma till exempel hur modeller ska lsas upp. Tyvrr r det inte alltid man kan bestmma vilket ramverk man ska ha och ibland s mste man vlja stora ramverk fr att man r beroende av ett stort CMS fr ngot projekt eller liknande och d r det inte s mycket att gra egentligen.

\emph{Det r vl ofta s inom valtech att kunden sger jag vill ha EPiServer eller liknande.}

Ja och d fr man gilla lget mer, men det r klart, fr man vlja sjlv s... Ska det vara ngonting litet tycker jag.

\emph{Jag har inte hunnit skaffa mig stenkoll p alla de hr. Grunt, har du anvnt det?}

Grunt r ett byggverktyg skulle man kunna sga. Vi anvnder det fr att kra testerna, d tar det hand om att starta en lokal server och att packa ihop en distribution. Det r ngot av en motsvarighet till Rubys Rake eller Javas Maven. Det r viktigt fr att det ska bli av att man kr tester och liknande, det mste vara ltt och tydligt hur man ndrar och drfr behver man bra byggverktyg.

\emph{Sen tnkte jag p stubbning med Sinon, vanillaJS och egentligen Jasmine ocks.}

VanillaJS r ju bara ett skmt, man driver med...

\emph{Nr du sjlv skriver funktioner och erstter...}

Ja, men terigen s r det samma princip som i att vlja sm ramverk, nr det gller mockning och stubbning s tycker jag att det r bra att anvnda JavaScript s lngt det gr. Vilket jag egentligen tycker gller fr alla sprk, ven i Ruby anvnder jag i frsta hand det som finns inbyggt i sprket.

\emph{Jag har lst en bok som r skriven av Christian Johansen som gjort SinonJS, Test-Driven JavaScript Development, dr hela boken gr ut p att man anvnder sig av manuell stubbning. Du sparar en kopia av en funktion, skriver ver den med en egen och terstller efter testet. Det r frst i sista kapitlet som han skriver och frresten, det finns det hr ramverket som jag rkar ha skrivit.}

Det ligger ju jttemycket i det, fr det r samma sak dr som fr andra ramverk. Annars sitter du dr och slss mot ett stubbningsramverk, helt ovrt, det r tid du aldrig kommer att f tillbaka. Dessutom blir det brckligt, ju fler dependencies du har desto brckligare blir det.

\emph{Jag insg ganska sent att Jasmine har spies, och du kan vlja om de ska anropa funktioner du stubbar eller inte, s varfr anvnde jag sinonJS d? Sen insg jag att Jasmine verkar terstlla alla metoder du stubbar automatiskt eftert, men det betyder ju ocks att jag inte kan stubba en sak, terstlla och stubba p ett annat stt i ett test. Lt oss sga att jag har en testsvit med en describe som jag har 20 test i och alla frutom ett stubbar en viss metod p ett visst stt, d blir det knepigt. Det kanske gr att komma runt, jag har inte frskt. Dr funderar jag p vad man ska ge fr rekommendation, fr det r nd det jag vill gra ngonstans, om du inte kommer gra det hr och det hr fancy grejerna s behver du inte sinonJS, du kan nja dig med Jasmine och att stubba manuellt.}

Jag tror att det r bra med exempel, dr man visar hur man kan lsa olika fall.

\emph{Tidigt i mitt arbete s insg jag att de exempel som finns r ofta vldigt grundlggande, s hr testar du ett hello world. Men det r ju inte det som folk r oroliga ver.}

Det dr r ocks problemet, fr ofta vill man ju demonstrera en princip som r lika sann fr hello world som jttestora JavaScript-applikationer. Folk gr det ofta vldigt ltt fr sig s det vore nog bra att frska hitta lite svrare fall, men inte krngla till det ondigt. Ofta gller samma principer, tricket r ju att lyckas separera det s bra att ditt test blir som ett hello world.

Om jag skulle skriva en bok s skulle jag inte vilja ha med mina tester. De skulle ju innebra en massa stubs som lyssnar p metodanrop som gr hrs och tvrs. Fr det r inte ngot jag r speciellt njd med utan det r s men jag nskar att det vore bttre skrivet. S det finns inte ngon situation dr jag kan rekommendera till ngon annan att skriv det hr testet utan snarare var smartare n vad jag r, skriv bttre kod och ls problemet p ett bttre stt.

Till slut s kommer man ner till problemet att man mste hitta bra abstraktioner. Nr det r precis rtt s blir det elegant. Drfr tror jag att mnga exempel r s korta, fr man r inte njd med de komplicerade testerna, det r inget man vill skryta med.

Sen r det ju s att nr man vl har insett varfr man vill testa och bestmt sig fr att gra det s kommer man vl komma fram, men det vore sknt om jag kunde gra den resan lite enklare fr folk.

Nej men ta fram bra exempel fr det dr om snt som du hittar p vgen, det tror jag r bra.

\emph{Just ja, du skrev spikes i vr mailkonversation, om hur du gr nr du inte vet hur du ska testa ngonting.}

Det r ett TDD-begrepp. Sg till exempel att man ska bygga ngot och det finns mnga oskerhetsfaktorer kring vad slutresultatet ska bli och vad som kommer att fungera. D r det anvndbart att ha versionshantering med Git, det r bara att skapa en ny branch och kra loss, skriv inte test utan gr bara. Kasta in grejer, prova, gr, kr hrt. Sen nr du har gaffat ihop din prototyp och den brjar fungera ngot snr, d gr du ur den branchen, gr en ny branch frn samma ursprungscommit och brjar om fast med tester. Det r att gra en spike.

Man vill inte ha fr lnga spikes, fr d blir det bkigt. Man ska inte sitta i tv veckor och sen kasta och gra om, utan det handlar bara om att hitta en riktning och en knsla fr hur man ska lsa problemet. Ofta r det s att man tror att det borde g om man tnker p ett visst stt och d kan man gra en snabb validering av det. Ofta kommer man till ett lge d man knner att det kommer att g att gra p ett visst stt, man r inte klar men brjar se hur saker och ting kommer att hnga ihop. D r det lge att avsluta sin spike och brja om med tester.

\emph{Hur undviker man knslan d av att man gr dubbelarbete?}

En motfrga r, vilken kod stter du dig och skriver en gng? Du itererar, det r bara att du tar en iteration tidigare, en spike kan vara den frsta iterationen av din kod. Det r jmt att typing is not the bottleneck, det r inte att skriva koden som tar tid, utan det som tar tid r att komma p hur man ska lsa problemet. Har man vl den lsningen, om man fattar vad som r rtt svar, d r det ganska ltt att skriva tester fr det och sen skriva koden. Det dr r intressant, fr dr kan man testa sig sjlv om det blir samma lsning om man testdriver ngot som nr man bara hver ur sig ngot.

\emph{Det r vl en vldigt bra grej. Jag tror att det r ngot som mnga upplever med TDD, att de inte har det hr verktyget och d str de dr och frsker komma p tester fr ngot som de inte har en aning om hur de tnker implementera.}

Dr har vi det igen, principer r inte till fr att begrnsa dig. Om man lter sig begrnsas s hamnar man i lget dr man knner sig oproduktiv, man mste ju tro p det man gr. Eller i varje fall vilja testa det, sen nr man kan reglerna s fr man bryta mot dem.

\emph{Du hade skrivit i ditt mail att du bara testar det publika API:et.}

Ja, och d menade jag publikt API i termer av att jag aldrig skulle skriva ett test fr en privat metod. Nu har man ju inte riktigt det i JavaScript, men...

\emph{Jag var nyligen hos Sony-mobile teamet och pratade med Kristoffer och han ville verkligen testa en privat metod. Det vi kom fram till var att vi kunde exponera den i testmiljn och gmma den i produktionsmiljn.}

Jo, men... Jag tycker nd inte att det r ett bra test. Fr det r en implementationsdetalj, det r som att testa variabelnamn. Om det blir fr stort s kanske man exponerar fel saker.  Man kanske vill ha ett annat API, dela upp i tv objekt till exempel, som har API:n sinsemellan. Jag tror att... det finns skert undantag. Vet man vad man gr, by all means, testa privata metoder, man kommer inte att hamna i TDD-domstolen fr det. Men generellt s r det en varningsflagga nr man vill skriva ett test fr en privat metod, d r det lge att tnka efter.

\emph{Min reaktion var att han kanske kan skapa en klass fr det som han vill testa. D var det tydligen tio rader kod och han var rtt njd med att det sg ut s.}

Jag hade nog inte gjort s, men det r ju en pgende diskussion och folk sger att de har ett case fr att gra det och visst jag kanske ngon gng hamnar i ett case dr jag knner att nu mste jag testa den hr privata metoden, men jag har inte varit dr n.

\emph{Jag hade planer p att skriva tester fr det vi gjorde i vras med konsultprofil-sidan, och dr hade vi mycket jQuery och anvnde module pattern. P ett felaktigt stt frmodligen. Nr jag sedan tittade p det hr och frgade mig hur jag ska kunna testa det s var det verkligen som du sa innan om legacy JavaScript att det inte gick att testa alls. De enda testerna jag kunde skriva var existerar den hr funktionen? och det r ju i princip att testa variabelnamn.}

Ja och det r ju ganska pointless (meningslst) egentligen, det kommer du inte ifrn. Den viktiga grejen med att inte testa privata metoder r att tester r till fr att kolla att saker blir rtt och i vrigt r du fri att gra vad du vill. Jag tnker att problemet med hans privata metod det r nr du kommer in i kodbasen och har ett mycket elegantare stt att lsa hans problem p, d finns det ett test som sger att den hr metoden mste fungera s hr och d kan du ju inte gra din eleganta lsning fr den mste ju tydligen gra s. D mste du g till ngon som vet och frga vad tanken bakom testet r fr att i bsta fall kunna vga ta bort det. Det r faran med att testa fr djupt.

\emph{Det kan jag nog knna med de tester jag skriver nu ocks, infr det hr workshopen, att det kan eventuellt uppst en sdan situation att jag har skrivit ett test utifrn en specifik implementation och missat pongen med den. Att hitta rtt niv att lgga sig p r inte ltt. Framfrallt inte nr man skriver tester i efterhand, vilket han ju ocks gjorde.}

Nej, det r ju inte det. D r det rtt hopplst. Man fr ven skilja p konceptet privat metod som i att det str private i koden och att det r en privat metod. I JavaScript s kan man inte gra en metod privat, men den kan nd vara tnkt att anvndas som om det vore det och inte r till fr att exponera. Det r bra om detta framgr i testerna.

\emph{Du kan testa att en metod r privat? *skratt*}

ven om du skulle flla in (inline) den metoden direkt i din kod s skulle testerna fortfarande g igenom. Koden gr fortfarande rtt ven fast den r skriven p ett annat stt.

\emph{Kodduplicering, nr man ser till att hlla testen korta s r det kanske inte ett lika stort problem om det bara r tre rader i varje test.}

Jag tycker att dr r lsbarhet viktigast. Man ska inte behva lsa 700 rader testkod fr att komma till krnan med det.

\emph{Det r mnga som sger att DRY-principen inte behver tillmpas p tester och det r samtidigt mnga som sger att tester behver vara maintainable.}

Det r absolut en avvgning, men jag tror helt klart att caset r annorlunda jmfrt med nr man skriver produktionskod. Det r ocks det hr med premature optimization, att folk anvnder DRY-principen fel, bde i test och i produktion. Om man tolkar det som att samma kodrad inte fr frekomma tv gnger i ett projekt s har man missat pongen, det handlar ju snarare om att man inte ska duplicera funktionalitet. Om tv olika saker rkar som en del av deras funktionalitet gra samma sak s betyder inte det att det ska dras ut till en metod, alltid. Det r likadant med tester, ofta r det s att saker ser vldigt lika ut, som att de gr samma sak, men ofta r s inte fallet. D hamnar man i dliga abstraktioner som i sjlva verket gr testerna mindre maintainable.

\emph{Det tycker jag ofta att man kan mrka, man tnker ok, om jag ska ta ut det hr till en separat metod, vad ska jag dpa den metoden till? Om namnet brjar innehlla villkor om det r s hr gr s hr och liknande s kanske det inte r rtt sak att gra.}

Dr kan jag ofta testa mig sjlv genom att gra kodduplicerings-spret och i efterhand frga mig hur lika de olika delarna blev. Ofta visar det sig att det inte var s mycket samma grej som man skulle gra i de olika situationerna. S det r en princip som har frstrts lite, det har p vissa hll gtt fr lngt och vergtt till att man kodgolfar.

\emph{Ja det r ju ofta man kan minska antalet rader kod och det r ju det folk brjar sikta p nu s. Det r vl det du menar med kodgolfning?}

Ja, precis, och det r inte alltid s bra.

\emph{Hur mycket tid har vi kvar frresten?}

Jag mste nog brja rra p mig.

\emph{Jag kan maila frgor om det r s.}

Ja men gr det, absolut. Hade du ngot mer?

\emph{Nej, inget viktigt.}

D ska jag nog brja dra mig. Men vad kul, det blir spnnande att se, du fr grna skicka ditt arbete till mig nr du r klar.

\subsection{Transcript of Interview with Patrik Stenmark}

\emph{Du skrev i ditt mail till mig att en nackdel med JavaScript r att det r mycket ceremoni fr ett dynamiskt typat sprk. Vad menade du med det?}

Jag borde kanske ha skrivit funktionellt sprk snarare n dynamiskt typat. Jag menar att det till exempel r ganska klumpigt syntaxmssigt att skicka med en anonym funktion i ett anrop. Du mste skriva function med parenteser, klammer, i vissa fall semikolon efter definitionen, 20 rader nedanfr, i andra fall ska det inte vara det, beroende p om det r ett objekt eller bara en funktion du definierar. Man behver fundera rtt mycket p syntax.

\emph{Det knner jag igen som har suttit rtt mycket med python, dr tycker jag att det r bttre.}

Jag r ju Ruby-utvecklare om jag fr vlja sjlv. Python r nnu renare, fr i Ruby finns det en del saker som man fr fundera p, men i JavaScript s r det s i stort sett hela tiden. Om man till exempel ska flytta en funktion frn att vara anonym till att bli en egen funktion fr att den har blivit fr stor, d r det inte bara att flytta den utan man behver ven fundera p om den hamnar i ett objekt s att det mste finnas kommatecken p rtt stlle eller om det blir en vanlig funktionsdefinition som ska avslutas med semikolon. Om den flyttas sist i ett objekt s ska det inte vara kommatecken, fr d blir det syntaxfel i vissa versioner av Internet Explorer. Det r mycket snt som jag tycker blir vldigt jobbigt. Visserligen finns JSLint och JSHint och liknande som kan hjlpa till, men det r fortfarande lite fr mycket saker som man inte borde behva tnka p.

\emph{Du skrev att du har anvnt JavaScript till bde sm saker och till lite strre. Tycker du att det lmpar sig bra till stora applikationer?}

Nej, *skratt*, egentligen inte. Jag tycker inte alls om JavaScript som sprk, jag tycker att det r alldeles fr mycket specialfall och konstiga quirks. Objectmodellen r vldigt konstig och knns schizofren i att man har ett prototyp-baserat system men ocks en new-operator som emulerar new-operatorn i Java, fast inte riktigt. Det r mycket sdana designbeslut som jag tycker r ganska konstiga. Dremot s r det ju ett sprk som finns tillgngligt verallt, s det gr att det nd funkar att hlla p med. Om det hade varit s att alla webblsare hade std att exekvera Ruby utan att frst ladda hem emscripten s skulle jag definitivt fredra det. Sen s finns det ju ramverk och grejer som hjlper till och gr att det fungerar bttre, men i grunden s nej, jag tycker inte att det r ett lmpligt sprk att skriva stora applikationer i.

\emph{S det r mest att det r enda alternativet?}

Ja.

\emph{Nu r jag inte helt insatt, men Single Page Applications (SPA) knns som en typisk grej dr JavaScript r enda valet.}

Ja, dr har du ju inte ngot alternativ egentligen. I varje fall s mste slutprodukten vara JavaScript. Den strsta grejen jag har gjort, som r en SPA, skrev jag i Coffeescript, men det r ju JavaScript.

\emph{Hur ser du p testning nr det kommer till stora program, blir det mer relevant d?}

Ja, definitivt.

\emph{Tror du att man klarar sig utan det verhuvudtaget?}

Ja klarar sig gr man ju, men utifrn min erfarenhet med en tidigare applikation som jag har jobbat med, som tog in statistik p ena sidan och byggde upp grafer som gick att filtrera p olika parametrar, s blev jag flera gnger hjlpt av testerna, srskilt nr ny funktionalitet skulle lggas till. D fanns det en bekrftelse p att jag inte hade haft snder ngonting tidigare och testerna manade mig till att skriva lite mer vlstrukturerat.

Frn vad jag sett i andra projekt s nr man inte har tester s blir det bara en stor soppa till slut dr varenda ndring man gr tar jttelng tid och har snder fyra andra funktioner. Fr att man inte var medveten om att en viss jQuery-handler mste kras fre en annan och s har man bytt plats p lite kod fr att ka lsbarheten och helt pltsligt funkar ingenting lngre.

\emph{Jag vet inte hur mycket du har hllit p med node?}

Ingenting.

\emph{Det jag funderat lite p r hur attityden gentemot testning har frndrats genom tiden, det knns som att node har varit en milstolpe som gjort att man brjat utveckla i JavaScript mer serist.}

Det har ju pverkat testning inom webb-JavaScript ocks, fr trots att jag aldrig har kodat fr node s har jag nd haft nytta av att ha en JavaScript-runtime tillgnglig som gjort att man kunnat kra testverktyg. Tidigare behvde man skriva en html-sida och ladda i webblsaren fr att kra sina JavaScript-tester. Det var ganska meckigt, att stta upp en ny testsvit var att stta upp en ny html-sida. Det node har gjort fr mig r att jag kan kra mina tester i terminal med PhantomJS eller Selenium beroende p vilken niv jag vill lgga det p. S p stt och vis har jag anvnt node, men jag har inte kodat node.

\emph{Varfr tror du att JavaScript-kodare ofta fredrar quick-and-dirty?}

Jag skyller p jQuery. *Skratt* Det har mycket att gra med hur JavaScript brjade, fr 10 r sen s hade du inte kunnat skriva en SPA fr du hade knappt AJAX men jag kan tnka mig att mnga har lrt sig JavaScript fr att kunna animera en knapp, vilket r enkelt att gra genom att skriva ngra f rader jQuery i en fil och inkludera den. Sen utvecklas det till att man vill ha lite mer menyer som expanderar och andra effekter vilket i sin tur vergr till att man implementerar faktiska funktioner i JavaScript. D har man lst tutorials p Internet som berttar att man skapar en viss handler i vilken man lser in ngot frn DOMen och manipulerar det och anvnder en selektor fr att hmta ut ett visst element och i det lget s r testbarheten i stort sett frlorad ven om man har en utvecklarbakgrund sedan tidigare.

Sen s tror jag att mnga JavaScript-utvecklare kommer frn designer-sidan, som inte har kunskaperna som krvs fr att riktigt veta vad det r de gr. De r designers som har lrt sig jQuery och kan det, utan att egentligen vara s insatta i programmering i stort. Sen s sitter de och lappar ihop saker och kan absolut vara asgrymma p jQuery och stadkomma jttehftiga effekter och bra saker p s stt, men de har inte strukturen och koddesign-tnket som man fr som utvecklare nr man bygger stora saker. Det har jag mrkt nr jag jobbat med frontend-utvecklare att de tycker att det r helt rimligt att ha en fil med 3000 rader kod med en funktion som r 250 rader lng som bara innehller DOM-uthmtning och AJAX-request och allting i en stor soppa. De tycker inte att det r ngot konstigt verhuvudtaget, fr det r s de har lrt sig. Tidigare har det varit vldigt lite information p Internet om hur man gr. Tutorials, dokumentation och liknande visar inte det utan det r de snabba lsningarna som visas oftast.

\emph{S, det har varit lite information om hur man gr det bra.}

Ja.

\emph{I ditt mail nmnde du ngra ramverk som du anvnt: Backbone, Ember, Angular. Framfrallt Backbone, vad jag fattade det som. Och s lite testning men Buster, Jasmine och Sinon. Nr tror du att de r lmpliga att anvnda sig av?}

Idag skulle jag nog inte anvnda Backbone verhuvudtaget, det var jttebra nr det kom men det knns som att det hade en hel del brister som har stannat kvar och sen s har det kommit en massa andra som har sett Backbone och tyckt att det varit bra men att vissa saker saknats och drfr gjort ngot nytt som r snppet bttre.

Det finns olika komplexitetsniver p det, Backbone r ju i den lgre skalan, det r vldigt simpelt egentligen. Den typen av ramverk knns rimliga nr det r sm applikationer. Kanske som en del av en strre site som hlls isolerad frn vriga delar av siten. Dremot s om man ska bygga en SPA-style s skulle jag nog inte g mot Backbone utan istllet utg frn hur komplext det r och vlja Angular eller CanJS om det var av medelstorlek eller Ember om det gller en applikation i stil med Gmail och avancerade forum-mjukvaror, som ska konkurrera med desktop-applikationer. Att dra fram Ember fr att gra en liten Todo-lista r bara overkill och ondigt.

\emph{Du tror inte att det r risk att det r i vgen nr det r s stort?}

Jo, det r det, men jag tror ocks att nr det r en s komplex applikation s r det vrt att ha ett ramverk som hjlper till rtt mycket, i synnerhet nr man mste anvnda JavaScript. Men absolut, jag r ju Rails-utvecklare och i den vrlden s r jag vldigt mycket inne p att frska frikoppla s mycket som mjligt frn Rails nr jag bygger saker. Jag har inte sett det gras ordentligt eller p ett bra stt i JavaScript-vrlden nnu. Det kanske gr, jag kanske ndrar mig om ett par r eller ngonting, men just nu s knns det som att det enklaste och mest effektiva r att ha ett ramverk som hjlper till rtt mycket. Sen kan man skert hamna i att man fr slss lite mot det eller anpassa vad man vill gra till vad ramverket klarar av.

\emph{Vad r de strsta vinsterna med de hr d, vad r det man fr hjlp med?}

Nr det gller Ember s fr du ju strukturen p applikationen, hur den ska byggas upp. Allting bygger p ngon slags state machine som styrs av vilken URL du r p. Sen att du fr en riktig MVC, eller i varje fall riktigare n de flesta andra ramverk, och att du har databindningarna bde p ren data och p det som kallas computer properties, s du kan ha en funktion som genererar ett vrde frn andra vrden som du ocks kan binda till DOM-element, vilket gr att mycket av situationen dr en hndelse ska trigga en mngd andra hndelser blir enklare.

Nr det gller de enklare verktygen s fr man frmst organisation och hjlp med boilerplate-kodning. Man vet vad vyer och controllers frvntas innehlla, vilket ger struktur.

\emph{Knner du att det hjlper fr att skriva tester ocks?}

*Tankepaus* Ja, det gr det ju. Det fr lite samma funktion, de hjlper varandra kan man sga. Du kan inte skriva tester fr dligt strukturerad kod utan att det blir komplicerat, s det hjlper ju dig att du redan har ngon form av struktur, men jag tror ocks att testerna hjlper dig att f nnu bttre struktur ven om du anvnder Backbone eller Ember. Fr du kan ju fortfarande skriva dlig kod i de ramverken, men d hjlper testerna till att frhindra det.

Om du inte hade ngot ramverk frn brjan s skulle du nog hamna i en bra struktur nd om du bara krde testdrivet. Jag pstr inte att det blir bra bara man har tester, men testerna kan hjlpa dig ven om du inte har ett ramverk. Bda hjlper frn varsitt hll.

\emph{Hur mycket har du testat just grnssnitt d?}

En del, men du har det inte varit s mycket i JavaScript utan mer Selenium frn Ruby. (Jag har skrivit tester med Jasmine som krs med Selenium aldrig s att alla tester krs via JavaScript.) Det r vldigt sllan vrt det, fr allting blir s knsligt fr frndringar i utseende, det r lngsamt och s fort du har ngon form av asynkronitet s fr du tester som failar ibland. Det kan bli s att de failar vissa tider p dygnet och kontentan blir att de gr mer skada n nytta fr att de inte gr att lita p och tar s lng tid att kra att man till slut inte orkar vnta p testerna.

Dremot s tror jag att det r bra att ha vldigt vergripande fr de viktigaste fldena. I mitt nuvarande projekt s har vi Selenium-tester fr de flden som har med pengar att gra trots att de involverar en del JavaScript, men vi testar inte att dropdown-menyer, vxling mellan olika vyer och liknande fungerar utan bara det absolut viktigaste som ett smoke test.

\emph{Vad menar du med smoke test?}

Att prova att g till sajten, se om den exploderar ungefr. Vldigt vergripande fr att se om standardfallet fungerar som det ska. Testa siten och se om det ryker frn den eller inte. *Skratt*

\emph{S det r just Selenium du har anvnt fr grnssnitt d?}

Ja, eller nej, inte bara. Jag har gjort en del genom att ladda in ngon form av template i ngon testhtml-sida och sen kra jQuery mot den div:en. D hamnar man i det som jag nmnde i mitt mail, att man behver hlla det i synk med vad som finns i produktion. Det kan bli s att man ndrar i designen p siten men att testerna fortfarande gr igenom eftersom de r baserade p templates som du har skapat trots att siten har blivit trasig. D har testerna krts av Selenium p en CI-maskin men det har inte varit Selenium som har klickat runt saker utan det anvnds bara fr att ladda sidan och sen har jQuery gjort resten.

\emph{Jag hade ngra fljdfrgor hr men de r inte s relevanta nu. Vi pratade i vr mailkonversation om externa APIer, du tyckte att det var svrt att testa dem. Vad r det som gr det svrt?}

Det r ju lite samma sak som med grnssnitt, att du har ett beroende p ngot som du sjlv inte har full kontroll ver. Facebook r till exempel knda fr att ndra i sina APIer lite hur som helst och nr som helst, nr de knner fr det. Det finns inget vettigt stt att testa dem mot live-miljn, fr du vill inte att du gr in och like:ar ngot tusen gnger per dag fr att du kr testerna hela tiden. D kan man frsts gra ngon slags mock och bara testa att rtt metoder anropas och s dr, men d har man problemet att om Facebook ndrar i sitt API s kommer ens tester fortfarande att g igenom men siten kommer inte att fungera.

Samma sak gller fr vilka APIer du n anvnder, det kan ven vara s med APIer du har sjlv, fr du vill ju inte kra dina enhetstester mot en riktig server fr d r de inte riktigt enhetstester lngre utan har blivit ngonting annat. Det r enklare nr det r APIer man sjlv har kontroll ver fr d kan man stta upp ngon slags integrationstestmilj som man anvnder bara infr release eller liknande fr att kontrollera att de mockade testerna fortfarande r uppdaterade. S gjorde jag nr jag arbetade med det dr statistikhanteringsverktyget som jag nmnde tidigare och det fungerade riktigt bra, kanske fr att det var ett API som jag sjlv byggde och hade full kontroll ver. S fort det blir ngot som man sjlv inte har kontroll ver s blir det mer komplicerat.

\emph{Det r vl s att privata APIer ndras nnu oftare och att det ytterligare spder p problemen med att den mockade datan kommer i osynk med den riktiga datan, s som du skrev i ditt mail till mig. Nr jag intervjuade Johannes Edelstam s freslog han att man kan ha tester som kontrollerar att ett objekt r ett korrekt request eller ett korrekt response, och kra dem bde p de riktiga objekten och p din fake som du har nr du mockar ett API. D mrker du att om testerna slutar g igenom p de riktiga objekten d behver du ndra p dem och d kommer de att brja faila p faken, och d ndrar du p faken, och d kommer de tester som faken anvnds i att faila. Har du anvnt dig av det ngonting?}

Inte i JavaScript-vrlden, men i Ruby-vrlden s gr jag det ofta nu fr tiden. Man behver oftast komma ut p Internet fr att kunna gra det, vilket ibland r ett problem och ibland inte. Jag hade ngon betalningslsning en gng dr det kostade pengar att gra testbetalningar, och d vill man frsts inte gra en testbetalning varje gng man kr sina tester. Men ibland s r det inga problem, om det till exempel gller en skning p Twitter s r det skert inga problem fr det fr du gra ganska mnga. Jag tycker absolut att det r en bra id och jag anvnder den sjlv nr jag jobbar med backend-kod, jag har dock inte provat det i JavaScript.

\emph{Du skrev i ditt mail att DOM-beroende tester blir lngsamma. Var det just Selenium du tnkte p d?}

Oavsett om du kr Selenium eller PhantomJS eller ngonting s r de ju lngsammare n rena JavaScript-tester.

\emph{r det fr att det r stora objekt som de skapar eller...?}

Ja, och DOM:en r ganska tung att jobba med, antar jag. Jag vet faktiskt inte varfr det gr lngsamt ven nr du kr Phantom, men det blir vl mer att gra helt enkelt. Det kanske inte r s jobbigt att kra ett test, men om du har 100 tester som r oberoende och varje test tar 100 ms s r du nd uppe i 10 s krtid. I mitt nuvarande projekt s har vi vl 6-700 enhetstester och om alla de skulle ta 100 ms s skulle vi ju ha blivit grhriga vid det hr laget. P enhetstestniv s blir det rtt mnga tester, i varje fall fr mig.

\emph{Vad strvar du efter d nr du har s mnga tester, frsker du tcka in mnga olika fall vill du bara ha ett test som talar om vad en sak ska gra?}

Nej, p enhetstestniv s vill jag ju tcka in allt i den mn det gr. Det r ett slags ml som jag vet inte riktigt gr att uppn, men nd det jag satsar p.

\emph{Just fr att kunna knna dig trygg sen nr du gr ndringar?}

Ja, precis. Nr jag ndrar och framfrallt nr andra ndrar. Om jag sitter sjlv p ett projekt s har jag oftast koll p vad som hnder, men nr man r flera personer, kanske geografiskt separerade som vi r i vrt nuvarande projekt med fem personer i Stockholm och tv p Malta, s r det en stor frdel om man kan frvissa sig om att ingen annan har haft snder ngonting genom att se att testerna fortfarande gr igenom.

\emph{Jag sg att du skrev p intrantet att du kom tillbaka frn semestern och fick stta dig och fixa tester, var det ngon annan som hade...?}

Ja, eller, det var ngon som hade stngt av testerna fr att det skulle fortstta vara grnt i Jenkins. Jag kpte inte riktigt det tankesttet. S fort man har tester som ibland inte fungerar, s kan man lika grna kasta dem, fr om de spontanfailar s att man inte kan lita p dem s blir det bara ondigt jobb.

\emph{Var det det som var fallet nu?}

Ja, en av testerna hade lite fr lg timeout tror jag att det var, s ibland hann den inte svara. Istllet fr att lsa det problemet s hade de bara stngt av alla testerna.

\emph{Det r vl viktigt att folk har samma ambitioner, kanske.}

Mm.

\emph{Du listade lite olika saker som du brukar ta hnsyn till nr du avgr vad du ska testa. Du sa att du gick mycket p knsla ocks, men. Hur relevant ngot var, det tolkade jag som att det var just funktionaliteten, hur relevant den var. Att om det r vldigt relevant s r det strre chans att du testar.}

Ja, som jag sa tidigare. Betalningsflden kr jag i Selenium fr att vara hundra p att det fungerar, men en liten dropdown-meny som visar kontaktinformation kanske jag bara fulhackar ihop med jQuery utan att skriva ngot test fr det. Sen finns det en skala drimellan.

\emph{Sannolikhet till frndring, om ngot frndras ofta, r det en anledning till att testa det?}

Ja, precis. Om vi vet att vi kommer att lgga till funktioner och ta bort och ndra s vill man se till s att det man har byggt fungerar, men om man vet att det r ngot man gr en gng och som sen kommer att ligga kvar dr, d tjnar man nog p att manuellt testa det s att det funkar och sen kommer det inte att frndras s drfr kan man lta det vara. Den r vldigt svr, fr man kan ju idag tro att ngot inte kommer att frndras och sen kommer en produktgare in imorgon och sger att det visst behver ndras. Det r ganska vanligt. I de flesta fall skulle jag skriva ngot vldigt ltt happy path-test bara fr att se till att ha den infrastrukturen p plats och frhoppningsvis s skulle personen som gr de hr ndringarna inse att det var dligt med tester just dr och skriva dem d. S frsker jag gra, att nr jag ska gra en ndring p ngot som r otestat s frsker jag, om det gr och passar in i projektkulturen, lgga upp det s att det fr ngon slags test runt sig.

\emph{Det vore ju grymt att ha en sn i teamet. *Skratt*}

Mm, men det krver ju att teamet gr det, inte att en person gr det, fr annars kommer den personen att bli galen efter ett tag. Om ingen annan gr det s kommer det att knnas som att alla andra har snder saker.

\emph{Hur mycket knner du att du fr med dig andra nr du gr s hr? Behver du slss fr att det ska bli som du vill?}

Det har varit vldigt olika p olika stllen. Allt frn va, ska man kra testerna ocks? till folk som aldrig har krt testdrivet tidigare men som nr man berttar frdelarna reagerar oh, det hr r ju det bsta jag har hrt talats om, det r klart vi ska gra det hr, och sen de som redan r medvetna om att det r bra sklart. Jag har varit tvungen att anpassa mig, p ngra projekt har jag velat gra mycket mer men ingen annan gr det och d tar jag hellre och gr mindre just fr att jag annars blir den som inte producerar ngon kod, jag skulle bara sitta och skriva tester. Som konsult s tycker jag att det viktigaste r att man anpassar sig till den redan existerande team-kulturen ven om jag aldrig skulle sluta frska vertala folk.

\emph{Men om man hamnar i en sdan situation att man nstan bara skriver tester, d lter det som att man skriver tester till existerande kod?}

Ja, precis. Det skrev jag vl ocks, att om det bara var ett nytt greenfield-projekt s skulle jag pusha ganska hrt fr att f ngon form av testkultur i teamet, men om man kommer in ngonstans dr det finns en massa kod som kanske inte r sdr vlskriven, det r d det tar tid att skriva testerna. D mste man ofta skriva om saker fr att f dem testbara.

Om man r den enda som vill gra det s kan det bli lite konstig stmning i teamet. Man sitter i tv dagar och skriver om kod s att den gr att testa, sen sitter man i tv dagar och skriver tester och sen gnar man en dag t att faktiskt gra det man skulle gra frn brjan. Om man dremot har ett team dr alla r med p det s tror jag att det r en vldigt bra sak fr du kan komma till ett lge d det gr lngsamt frsta tiden men ju lngre man kommer desto snabbare gr utvecklingen fr att man blir skrare p att man inte har snder saker och man kan skriva om kod s att den blir mer lttfrstdd. Det r i s fall en lngtidsinvestering, som man inte kan gra som enskild team-medlem.

\emph{Du nmnde komplexitet ocks, det framgick inte om det var komplex kod du syftade p eller om det var komplexa tester. Jag gissar att om det r vldigt komplex kod s vill man testa den och om det blir komplexa tester s vill man kanske inte ha dem.}

Ja, precis. Det skrev jag vl ocks ngonstans om det hr med bra och dliga tester, att man vill ha s lttfrstdda och s enkla okomplicerade tester som mjligt. Om det r ett komplicerat flde s blir ju testerna oftast komplicerade, men man kan nd strva efter att ha s enkla tester som mjligt. Vad gller att bestmma vad som ska testas s r det nog nd i frsta hand komplexiteten i det som ska testas som avgr, bde i termer av komplexa algoritmer och affrsregler, det kan vara ganska enkel kod men mnga olika regler som spelar in. Ju mer komplext desto mer tester.

\emph{Du skrev ngonstans att man ska lyssna p testerna. Vad menar du med det?}

Det gr ihop med att jag tycker att tester r mer ett designverktyg n ett verifikationsverktyg. Lt oss sga att jag har ett test som krver 70 rader setup-kod fr att f alla beroenden uppsatta och jag mste initiera 17 olika objekt med 10 parametrar var bara fr att kunna testa att jag fr ut Hello World p skrmen, d kanske jag har en dlig arkitektur som jag borde frenkla eller frndra p ngot stt. Nr man brjar hamna dr s gller det att lyssna p att det r ngonting som brjar bli jobbigt, ta ett steg tillbaka och brja fundera p vad det egentligen r man hller p med och om det gr att frenkla. Kanske introducera ngot nytt objekt som tar hand om lite av det ansvar som jag hller p med nu, eller ndra ansvarsomrden fr de redan existerande objekten, istllet fr att bara kra p och pressa in nnu mer saker.

\emph{Hur tror du att det hr hnger ihop med hur enkelt det r att kra tester?}

Jag vet inte om det hnger ihop s jttemycket med att kra testerna, eller, p ngon niv gr det vl det.

\emph{Hur resultatet presenteras.}

Ja, allts...

\emph{Eller r det mer vid sjlva skrivandet av testerna som man behver knna av sdant hr?}

Ja, fast det r bde och, det finns olika niver p beroenden. Nr det handlar om att stta upp ett enskilt test s handlar det ofta om beroenden mellan klasser och objekt, dr har det inte s mycket att gra med att kra dem, men man kan ju dremot ha beroenden p en hgre niv: Jag mste ha en Java-applikationsserver igng fr att kunna kra de hr testerna och den mste vara konfigurerad p det hr sttet med de hr instllningarna. Det tycker jag ocks r ett beroende p ngonting som krver en massa setup, men d r det ju p en hgre niv. Jag tror att man vill undvika den typen av beroenden s lngt som mjligt.

I idealfallet s tycker jag att man ska kunna checka ut koden och kra ett kommando s ska testerna kra. Det r inte alltid ltt att hamna dr, men det r det som r mlet, p samma stt som jag tycker att 100 \% test coverage r ml som man ska strva mot s tycker jag att man ska strva mot att ha tester som man kan kra nr som helst utan att behva starta upp servrar och liknande. Om man vill ha ordentliga integrationstester s r det oftast svrt, eller omjligt, men det ska nd inte krva att man startar upp en specifik tomcat-server manuellt utan allt ska sktas av test runnern.

\emph{Jo, att automatisera kan verkligen vara guld vrt, d blir det att man kr testerna oftare ocks, s att man verkligen fr ut mer vrde av dem, mer feedback. Vi pratade lite om hur det pverkar sttet man jobbar p, om man har tester jmfrt med om man inte har det. Om vi tnker oss att du har en kund som tycker att testning r en bra sak, hur pverkar det hur du jobbar?}

Om man bortser frn alla andra faktorer, s tror jag att man kan jobba mycket mer med refaktorisering och kodkvalitet om man har en vettig testkultur, fr att man kan vara mer sker p att frndringar man gr inte har snder ngonting. Det tror jag betalar sig i lngden, fr man kan hlla hgre hastighet.

\emph{Man blir mer flexibel ocks.}

Ja, den andra biten r att man frhoppningsvis fr en bttre arkitektur som gr leder till ett mer flexibelt system. Man kan ta till sig nya krav istllet fr att vissa saker inte gr att gra i det system som man har byggt. Ny funktionalitet kan fortfarande ta tid att implementera, men frhoppningsvis s finns det alltid en mjlighet. Det finns frsts en mngd andra faktorer som ocks spelar in fr att man ska kunna stadkomma hg kodkvalitet, men en bra testkultur r helt klart ett steg i rtt riktning. Man behver fortfarande anstrnga sig, men det blir enklare att gra det med testning.

\emph{Vad tror du om att anvnda tester som ett kommunikationsredskap? Bde gentemot kund och nya utvecklare.}

Det lter vldigt bra. *Skratt* Jag har aldrig upplevt att det har fungerat.

\emph{Om du tittar p ngon annans kod och det finns tester, kollar du p dem frst d eller frsker du frst koden frst?}

Jag brukar kolla p testerna, men de brukar vldigt sllan vara skrivna p ett stt som gr det uppenbart.

\emph{Det tnkte jag p innan nr du sa det hr med att man frsker tcka in s mycket som mjligt med sina enhetstester, att det skulle kunna finnas en vits med att skriva ganska enkla enhetstester som inte alls har ambitionen att hitta alla buggar utan istllet r tnkta mer som en specifikation.}

Jag tycker att om man har ett vettigt testverktyg s kan man dra upp det p olika niver, bde Buster och Jasmine har ju nstlade describe-block, s att man kan skilja grundfunktionaliteten frn specialfallen. Det r ngot som jag vill bli bttre p fr det r riktigt bra nr det fungerar, som i vissa Open Source-projekt. Jag har aldrig sett ett kundprojekt dr det har varit s.

RSpec och Cucumber har s att deras webbsite r deras features i ett mer webbvnligt format, vilket r hftigt. Vi har ven boken Specification by Example av Gojko Adzic som tar upp mycket av det. Jag tror att det p vissa stllen skulle vara vldigt vrdefullt att tnka s, i synnerhet ut mot resten av organisationen men ven p enhetstestniv. Jag vill trna p det mer och faktiskt kunna f till sdana tester som gr att man kan frst hur allting fungerar direkt utifrn att kra spec-outputen.

Testning r sjukt svrt, jag har frskt kra ngon form av testdriven utveckling i sex r och jag tycker inte att jag riktigt kan det nnu. Det kan vara s att dligt skriva tester r smre n inga tester, fr de r ofta s beroende av implementationen att frdelarna av att kunna ndra p saker uteblir fr att en ndring av implementationen gr att testerna slutar fungera. D har du tester som bara r i vgen, och samma sak blir det nr du inte lyssnar p dina tester. Du hamnar i att du har beroenden mellan allting, men i testerna s stts allting upp och drfr gr de nd igenom. D blir det s att du ndrar en sak och allting nd gr snder, s att man blir frustrerad ver att behva fixa tester som slutar fungera av helt orelaterade anledningar. I de lgena r det kanske bttre att inte ha ngra tester alls, och det var dr jag var fr kanske fem r sedan. Jag hittade kod frn den tiden fr ett r sedan dr vi hade Ruby-tester med 160 raders setup-block fr att stta upp nstan alla objekt i hela applikationen. Jag minns att vi svor dagligen ver de testerna fr att de kndes i vgen och ondiga. Det r svrt. Det r nnu svrare i JavaScript, fr dr har man en DOM som har en tendens att komma in verallt.

\emph{Sista frgan var just vad du skulle ge fr tips till ngon som vill brja testa sin JavaScript.}

Frsk inte att gra det p redan existerande kod, r vl det frsta. I princip enda sttet du kan testa en jQuery-byggd site r med Selenium eller en liknande helt integrerad lsning. Det r inte vrt att frska g in och skriva enhetstester med en DOM inblandad. Sen skulle jag ta det steg fr steg, s att man skriver tester fr de delar man r inne och meckar i.

Vad gller att lra sig s har Katas fungerat vldigt bra fr mig. Genom att kra kodkatas s kan man lra sig grunderna, som behvs fr att man inte ska f det vldigt jobbigt. Brja med de enkla fallen, som att testa en strngomvndare och liknande. D slipper du lra dig alla saker samtidigt, och kan istllet fokusera p att lra dig testramverket frst och sen lgga p saker allt eftersom. Det r ocks vldigt givande om du har ngon som kan mycket som du kan sitta tillsammans med.

Brja ngonstans, anvnd tester i egna projekt eller kundprojekt om det finns tillrckligt std frn resten av teamet. Ngonting nytt d, inte ngot som redan har massor med JavaScript, fr d blir det bara jobbigt.

\emph{Jag tnker ocks p det nu nr jag kommer in i Live, dr det just nu finns en ambition om att brja testa mer. Hur det kommer att g till dr, vad tror du skulle vara lmpligt?}

Det r svrt att sga allmnt.

\emph{Det jag knner spontant r vl just det att man ser till att skriva tester fr det man gr in och ndrar.}

Ls refactoring-boken och jobba med att kontinuerligt frbttra kodbasen, fr det rcker inte med att skriva ett test och sedan knna sig njd. Annars kommer du att ha en testsvit p flera hundra tester som tar flera minuter att kra lokalt och d kommer ingen att orka kra dem. Du kanske har en CI-maskin som kr testerna varje natt.

\emph{Selenium tnker jag frska undvika, frutom fr det absolut mest kritiska.}

Det r oftast dit du mste g om du inte brjar frbttra kodstrukturen, annars blir det ofta s att man inte kommer undan att behva kolla i sin DOM ngonstans. Jag ska inte sga att du inte ska vara rdd fr att strukturera om kod, fr det kommer man att vara, men gr det nd. Det spelar egentligen ingen roll om det r .NET-kod eller JavaScript-kod, samma principer gller nd. Se till att automatisera allt, fr annars kommer ingen att orka kra testerna.

Brja med instllningen att stoppa produktionslinan om testerna gr snder, som i Toyota-fabrikerna. Inte skjuta p att fixa tester som gtt snder. Det har med kulturen att gra, man mste f alla med p det. Det r problem jag haft p mnga stllen att folk sger att de vill gra det och r vldigt positiva nr man pratar om det men sedan s mrker man att vissa tester p byggservern har varit rda i nstan ett dygn och fr ett svvande svar om att det ska fixas imorgon nr man frgar varfr det blivit s. D hamnar man i att ingen litar p testerna efter ett tag, fr att man inte vet om det r rtt fr att ngot r trasigt eller fr att testerna inte har uppdaterats p grund av att ngon inte frstod ngonting. S fort man fr den oskerheten s gr testernas vrde ner ganska hrt.

\emph{Tack ska du ha!}

\end{document}



